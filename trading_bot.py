#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bot Giao d·ªãch T·ª± ƒë·ªông AI/ML Ti√™n ti·∫øn
====================================
Bot giao d·ªãch t·ªïng h·ª£p c√°c c√¥ng ngh·ªá AI/ML v·ªõi ki·∫øn tr√∫c Master-Specialist
T√≠ch h·ª£p Reinforcement Learning, Ensemble Models v√† Sentiment Analysis
Author: AI Assistant
Version: 2.0.0
"""

import asyncio
import aiohttp
import pandas as pd
import numpy as np
import requests
import sqlite3
import logging
import warnings
import os
import sys
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import threading
import queue

# Machine Learning Libraries
import sklearn
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import MinMaxScaler
import xgboost as xgb
import lightgbm as lgb
import optuna

# Deep Learning
import tensorflow as tf

# Force CPU-only mode to avoid CUDA errors
try:
    # Hide GPU devices
    tf.config.set_visible_devices([], 'GPU')
    # Set CPU threading
    tf.config.threading.set_inter_op_parallelism_threads(0)  # Use all CPU cores
    tf.config.threading.set_intra_op_parallelism_threads(0)  # Use all CPU cores
    print("‚ö†Ô∏è  Running in CPU-only mode (No GPU available)")
except Exception as e:
    print(f"‚ö†Ô∏è  TensorFlow configuration warning: {e}")

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Attention, BatchNormalization, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Reinforcement Learning
import gymnasium as gym
from gymnasium import spaces
import stable_baselines3
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.vec_env import DummyVecEnv

# Technical Analysis
import ta
from ta import add_all_ta_features
from ta.volatility import AverageTrueRange
from ta.trend import ADXIndicator
from ta.momentum import RSIIndicator

# Online Learning
from river import linear_model, preprocessing, anomaly

# Suppress warnings and CUDA errors
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all TensorFlow logs
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable CUDA devices
os.environ['TF_DISABLE_GPU'] = '1'  # Additional flag to disable GPU
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable OneDNN optimizations
os.environ['TF_DISABLE_MKL'] = '1'  # Disable Intel MKL
os.environ['TF_DISABLE_POOL_ALLOCATOR'] = '1'  # Disable pool allocator

# Set UTF-8 encoding
sys.stdout.reconfigure(encoding='utf-8')

# ===== C·∫§U H√åNH API V√Ä CONSTANTS =====
class Config:
    """Qu·∫£n l√Ω c·∫•u h√¨nh to√†n c·ª•c
    
    NOTE: API Keys below may be expired/invalid for demo purposes.
    For production use, replace with valid API keys from respective services.
    """
    
    # API Keys
    ALPHA_VANTAGE_API_KEY = "FK3YQ1IKSC4E1AL5"
    FINNHUB_API_KEY = "YOUR_VALID_FINNHUB_KEY_HERE"  # Invalid - replace with real key
    MARKETAUX_API_KEY = "CkuQmx9sPsjw0FRDeSkoO8U3O9Jj3HWnUYMJNEql"
    NEWSAPI_API_KEY = "abd8f43b808f42fdb8d28fb1c429af72"
    EODHD_API_KEY = "68bafd7d44a7f0.25202650"
    OANDA_API_KEY = "814bb04d60580a8a9b0ce5542f70d5f7-b33dbed32efba816c1d16c393369ec8d"
    GEMINI_API_KEY = "AIzaSyAdrWcXyYHhQb1F8K2P3L4N5M6O7P8Q9R0"  # Replace with actual key
    
    # Endpoints
    OANDA_URL = "https://api-fxtrade.oanda.com/v3"
    DISCORD_WEBHOOK = "https://discord.com/api/webhooks/1419645732218081290/xamfJQdl5kay1wo6w6gxQRrW77d1jpSzKBstQ16Qvb4t5ncGJ3nIHMmm3MQPNT_E-Bt2"
    
    # Trading Symbols
    SYMBOLS = ["XAUUSD", "EURUSD", "NAS100", "BTCUSD"]
    SYMBOL_MAPPING = {
        "NAS100": "NAS100_USD", 
        "EURUSD": "EUR_USD",   # Try EUR_USD first
        "XAUUSD": "XAU_USD",   # OANDA gold symbol 
        "BTCUSD": "BTC_USD"    # OANDA Bitcoin symbol
    }
    # Alternative mappings for different brokers/APIs
    ALTERNATIVE_SYMBOLS = {
        "XAUUSD": ["XAU_USD", "XAUUSD", "GOLD"],
        "BTCUSD": ["BTC_USD", "BTCUSD", "BTC"],
        "EURUSD": ["EUR_USD", "EURUSD", "USDEUR"],  # Try both formats
        "NAS100": ["NAS100_USD", "NAS100", "NAS_USD"]
    }
    
    # Risk Management
    MAX_POSITION_SIZE = 0.02  # 2% per trade
    MAX_CORRELATION_THRESHOLD = 0.7
    STOP_LOSS_MULTIPLIER = 2.0
    TAKE_PROFIT_MULTIPLIER = 3.0
    
    # Database
    DB_PATH = "trading_bot.db"
    
    # Model Parameters
    TIME_FRAMES = ["M15", "H1", "H4", "D1"]
    FEATURE_WINDOW = 50
    PREDICTION_HORIZON = 1

# ===== H·ªÜ TH·ªêNG LOGGING N√ÇNG CAO =====
class ColorFormatter(logging.Formatter):
    """Formatter v·ªõi m√†u s·∫Øc cho console logging"""
    
    COLORS = {
        'DEBUG': '\033[94m',    # Blue
        'INFO': '\033[92m',     # Green
        'WARNING': '\033[93m',  # Yellow
        'ERROR': '\033[91m',    # Red
        'CRITICAL': '\033[95m', # Magenta
    }
    RESET = '\033[0m'
    
    EMOJI_MAP = {
        'DEBUG': 'üîç',
        'INFO': '‚úÖ',
        'WARNING': '‚ö†Ô∏è',
        'ERROR': '‚ùå',
        'CRITICAL': 'üö®'
    }
    
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, '')
        emoji = self.EMOJI_MAP.get(record.levelname, 'üìù')
        reset_color = self.RESET
        
        # Format th·ªùi gian
        fmt_time = datetime.now().strftime('%H:%M:%S')
        
        # Format level v·ªõi m√†u v√† emoji
        colored_level = f"{log_color}{emoji} {record.levelname:<8}{reset_color}"
        
        # Format message
        message = f"{log_color}{record.getMessage()}{reset_color}"
        
        return f"[{fmt_time}] {colored_level} [{record.name}] {message}"

class EnhancedLogManager:
    """Qu·∫£n l√Ω logging n√¢ng cao v·ªõi ph√¢n t√°ch module"""
    
    def __init__(self):
        self.loggers = {}
        self.setup_logging()
    
    def setup_logging(self):
        """Thi·∫øt l·∫≠p h·ªá th·ªëng logging ch√≠nh"""
        
        # T·∫°o root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)
        
        # Console handler v·ªõi m√†u s·∫Øc
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.DEBUG)
        console_handler.setFormatter(ColorFormatter())
        root_logger.addHandler(console_handler)
        
        # File handler cho file log ch√≠nh
        file_handler = logging.FileHandler('trading_bot.log', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        root_logger.addHandler(file_handler)
        
        # T·∫°o c√°c logger chuy√™n bi·ªát cho t·ª´ng module
        modules = [
            'BotCore', 'DataManager', 'FeatureEngineer', 'NewsManager',
            'EnsembleModel', 'RLAgent', 'MasterAgent', 'RiskManager', 'Discord'
        ]
        
        for module in modules:
            logger = logging.getLogger(module)
            logger.setLevel(logging.DEBUG)
            self.loggers[module] = logger
    
    def get_logger(self, module_name: str) -> logging.Logger:
        """L·∫•y logger cho module c·ª• th·ªÉ"""
        return self.loggers.get(module_name, logging.getLogger(module_name))
    
    def get_log_summary(self) -> Dict[str, Any]:
        """T·∫°o b√°o c√°o t√≥m t·∫Øt t·ª´ log files"""
        try:
            with open('trading_bot.log', 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            error_count = sum(1 for line in lines if 'ERROR' in line)
            warning_count = sum(1 for line in lines if 'WARNING' in line)
            info_count = sum(1 for line in lines if 'INFO' in line)
            
            return {
                'total_entries': len(lines),
                'errors': error_count,
                'warnings': warning_count,
                'info_messages': info_count,
                'last_updated': datetime.now().isoformat()
            }
        except Exception as e:
            return {'error': f'Kh√¥ng th·ªÉ ƒë·ªçc log file: {e}'}

# Kh·ªüi t·∫°o h·ªá th·ªëng logging
LOG_MANAGER = EnhancedLogManager()

# ===== QU·∫¢N L√ù API V√Ä MONITORING =====
@dataclass
class APIHealth:
    """Tr·∫°ng th√°i s·ª©c kh·ªèe c·ªßa API"""
    name: str
    status: str
    response_time: float
    last_check: datetime
    error_count: int = 0
    success_count: int = 0

class APIMonitoringSystem:
    """Theo d√µi s·ª©c kh·ªèe c·ªßa c√°c API"""
    
    def __init__(self):
        self.api_health: Dict[str, APIHealth] = {}
        self.logger = LOG_MANAGER.get_logger('BotCore')
    
    def update_api_health(self, api_name: str, status: str, response_time: float):
        """C·∫≠p nh·∫≠t tr·∫°ng th√°i s·ª©c kh·ªèe API"""
        now = datetime.now()
        
        if api_name not in self.api_health:
            self.api_health[api_name] = APIHealth(api_name, status, response_time, now)
        else:
            health = self.api_health[api_name]
            health.status = status
            health.response_time = response_time
            health.last_check = now
            
            if status == 'healthy':
                health.success_count += 1
            else:
                health.error_count += 1
    
    def get_unhealthy_apis(self) -> List[str]:
        """L·∫•y danh s√°ch API kh√¥ng kh·ªèe m·∫°nh"""
        unhealthy = []
        for name, health in self.api_health.items():
            if health.error_count > health.success_count or health.response_time > 5.0:
                unhealthy.append(name)
        return unhealthy

class APIManager:
    """Qu·∫£n l√Ω t·∫•t c·∫£ API calls v·ªõi rate limiting v√† retry logic"""
    
    def __init__(self):
        self.session = None
        self.rate_limits = {}  # API name -> {last_call: time, next_allowed: time}
        self.monitor = APIMonitoringSystem()
        self.logger = LOG_MANAGER.get_logger('BotCore')
        self.retry_count = 3
        self.timeout = 10
        
        # Rate limit settings (requests per minute) - More conservative
        self.rate_limit_config = {
            'oanda': 15,  # Further reduced to be very conservative
            'finnhub': 30,  # Reduced
            'newsapi': 500,  # Reduced
            'alpha_vantage': 3,  # Reduced
            'marketaux': 50,  # Added
            'yahoo_finance': 1000  # Added
        }
    
    async def __aenter__(self):
        """Async context manager entry"""
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=30)
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        self.session = aiohttp.ClientSession(connector=connector, timeout=timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        if self.session:
            await self.session.close()
            self.session = None
    
    async def close(self):
        """Close the session manually"""
        if self.session:
            await self.session.close()
            self.session = None
    
    def _check_rate_limit(self, api_name: str) -> bool:
        """Ki·ªÉm tra rate limit cho API"""
        if api_name not in self.rate_limits:
            return True
    
        now = time.time()
        limit_info = self.rate_limits[api_name]
        
        # N·∫øu ƒë√£ qua th·ªùi gian cho ph√©p call ti·∫øp
        if now >= limit_info['next_allowed']:
            return True
        
        return False
    
    def _update_rate_limit(self, api_name: str):
        """C·∫≠p nh·∫≠t th·ªùi gian rate limit"""
        now = time.time()
        rate_per_minute = self.rate_limit_config.get(api_name, 60)
        interval = 60.0 / rate_per_minute
        
        if api_name not in self.rate_limits:
            self.rate_limits[api_name] = {'last_call': now, 'next_allowed': now + interval}
        else:
            limit_info = self.rate_limits[api_name]
            limit_info['last_call'] = now
            limit_info['next_allowed'] = now + interval
    
    async def _make_request(self, url: str, headers: Dict = None, 
                          params: Dict = None, api_name: str = 'generic') -> Optional[Dict]:
        """Th·ª±c hi·ªán HTTP request v·ªõi retry logic"""
        
        # Ki·ªÉm tra session v√† t·ª± ƒë·ªông kh·ªüi t·∫°o l·∫°i n·∫øu c·∫ßn
        if not self.session or self.session.closed:
            self.logger.warning(f"Session is closed cho {api_name}, ƒëang kh·ªüi t·∫°o l·∫°i...")
            # Properly close existing session before creating new one
            if self.session and not self.session.closed:
                await self.session.close()
            await self.__aenter__()
        
        # Ki·ªÉm tra rate limit
        if not self._check_rate_limit(api_name):
            limit_info = self.rate_limits.get(api_name, {})
            wait_time = limit_info.get('next_allowed', 0) - time.time()
            if wait_time > 0:
                self.logger.warning(f"Rate limit cho {api_name}, ch·ªù {wait_time:.1f}s...")
            return None
        
        start_time = time.time()
        
        for attempt in range(self.retry_count):
            try:
                async with self.session.get(url, headers=headers, params=params) as response:
                    response_time = time.time() - start_time
                    
                    if response.status == 200:
                        self._update_rate_limit(api_name)
                        self.monitor.update_api_health(api_name, 'healthy', response_time)
                        
                        data = await response.json()
                        return data
                    else:
                        self.logger.warning(f"API {api_name} tr·∫£ v·ªÅ status {response.status}")
                        
                if attempt < self.retry_count - 1:
                    wait_time = 2 ** attempt  # Exponential backoff
                    self.logger.info(f"Retry {attempt + 1}/{self.retry_count} cho {api_name}, ch·ªù {wait_time}s...")
                    await asyncio.sleep(wait_time)
            
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout cho {api_name}, attempt {attempt + 1}")
            except aiohttp.ClientError as e:
                if "Session is closed" in str(e):
                    self.logger.warning(f"Session closed cho {api_name}, attempt {attempt + 1}")
                    # Recreate session for next attempt
                    if self.session:
                        await self.session.close()
                    await self.__aenter__()
                else:
                    self.logger.error(f"Client error cho {api_name}: {e}")
            except Exception as e:
                self.logger.error(f"L·ªói API call {api_name}: {e}")
        
        self.monitor.update_api_health(api_name, 'unhealthy', time.time() - start_time)
        return None

# ===== QU·∫¢N L√ù D·ªÆ LI·ªÜU N√ÇNG CAO =====
@dataclass
class DataFreshnessInfo:
    """Th√¥ng tin ƒë·ªô m·ªõi c·ªßa d·ªØ li·ªáu"""
    symbol: str
    timeframe: str
    last_update: datetime
    is_fresh: bool
    age_minutes: float
    threshold_minutes: float = 30  # Ng∆∞·ª°ng coi d·ªØ li·ªáu l√† c≈© (ph√∫t)

class EnhancedDataFreshnessManager:
    """Qu·∫£n l√Ω ƒë·ªô m·ªõi c·ªßa d·ªØ li·ªáu"""
    
    def __init__(self):
        self.freshness_data: Dict[str, DataFreshnessInfo] = {}
        self.logger = LOG_MANAGER.get_logger('DataManager')
    
    def update_symbol_data(self, symbol: str, timeframe: str, last_update: datetime):
        """C·∫≠p nh·∫≠t th·ªùi gian d·ªØ li·ªáu cu·ªëi c√πng cho symbol"""
        key = f"{symbol}_{timeframe}"
        age_minutes = (datetime.now() - last_update).total_seconds() / 60
        
        self.freshness_data[key] = DataFreshnessInfo(
            symbol=symbol,
            timeframe=timeframe,
            last_update=last_update,
            is_fresh=age_minutes < 30,
            age_minutes=age_minutes,
            threshold_minutes=30
        )
    
    def get_stale_symbols(self) -> List[str]:
        """L·∫•y danh s√°ch symbols c√≥ d·ªØ li·ªáu c≈©"""
        stale_symbols = []
        for info in self.freshness_data.values():
            if not info.is_fresh:
                stale_symbols.append(info.symbol)
        return stale_symbols
    
    def refresh_needed(self, symbol: str, timeframe: str) -> bool:
        """Ki·ªÉm tra xem c√≥ c·∫ßn l√†m m·ªõi d·ªØ li·ªáu kh√¥ng"""
        key = f"{symbol}_{timeframe}"
        if key not in self.freshness_data:
            return True
        
        info = self.freshness_data[key]
        return not info.is_fresh

class EnhancedDataManager:
    """Qu·∫£n l√Ω d·ªØ li·ªáu ƒëa khung th·ªùi gian v·ªõi freshness checking"""
    
    def __init__(self, api_manager: APIManager):
        self.api_manager = api_manager
        self.freshness_manager = EnhancedDataFreshnessManager()
        self.logger = LOG_MANAGER.get_logger('DataManager')
        self.data_cache = {}  # symbol_timeframe -> DataFrame
    
    def _get_oanda_symbol(self, symbol: str) -> str:
        """Chuy·ªÉn ƒë·ªïi symbol sang ƒë·ªãnh d·∫°ng OANDA"""
        return Config.SYMBOL_MAPPING.get(symbol, symbol)
    
    async def fetch_market_data(self, symbol: str, timeframe: str, count: int = 500) -> Optional[pd.DataFrame]:
        """L·∫•y d·ªØ li·ªáu th·ªã tr∆∞·ªùng t·ª´ OANDA API v·ªõi fallback symbols"""
        
        # Try multiple symbol mappings for better compatibility
        for symbol_variant in Config.ALTERNATIVE_SYMBOLS.get(symbol, [symbol]):
            try:
                # Check if this variant is supported by Oanda
                if symbol_variant not in Config.SYMBOL_MAPPING:
                    continue
                    
                oanda_symbol = self._get_oanda_symbol(symbol_variant)
                url = f"{Config.OANDA_URL}/instruments/{oanda_symbol}/candles"
                
                # Map timeframe to OANDA format
                tf_mapping = {"M15": "M15", "H1": "H1", "H4": "H4", "D1": "D"}
                params = {
                    'count': min(count, 5000),  # OANDA limit
                    'granularity': tf_mapping[timeframe],
                    'price': 'M'  # Mid only - ƒë∆°n gi·∫£n h√≥a
                }
                
                headers = {
                    'Authorization': f'Bearer {Config.OANDA_API_KEY}',
                    'Content-Type': 'application/json',
                    'Accept-Datetime-Format': 'RFC3339'  # OANDA recommended header
                }
                
                self.logger.info(f"Fetching {symbol} ({oanda_symbol}) {timeframe} data from OANDA...")
                data = await self.api_manager._make_request(url, headers=headers, params=params, api_name='oanda')
                
                if data and 'candles' in data:
                    df = self._process_oanda_data(data['candles'])
                    cache_key = f"{symbol}_{timeframe}"
                    self.data_cache[cache_key] = df
                    
                    # C·∫≠p nh·∫≠t freshness
                    now = datetime.now()
                    self.freshness_manager.update_symbol_data(symbol, timeframe, now)
                    
                    self.logger.info(f"ƒê√£ l·∫•y {len(df)} candles cho {symbol} {timeframe}")
                    return df
                elif data and 'errorMessage' in data:
                    self.logger.warning(f"Oanda API error for {symbol_variant} ({oanda_symbol}) {timeframe}: {data['errorMessage']}")
                    # Continue to next variant
                else:
                    self.logger.warning(f"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho {symbol_variant} ({oanda_symbol}) {timeframe}")
                    # Continue to next variant
                    
            except Exception as e:
                self.logger.warning(f"L·ªói khi fetch {symbol_variant} ({symbol_variant}): {e}")
                # Continue to next variant
        
        # If all variants failed, try alternative APIs
        self.logger.warning(f"OANDA variants cho {symbol} th·∫•t b·∫°i, th·ª≠ alternative APIs...")
        return await self._fetch_alternative_api(symbol, timeframe, count)
    
    async def _fetch_alternative_api(self, symbol: str, timeframe: str, count: int = 500) -> Optional[pd.DataFrame]:
        """Fetch data from alternative APIs (Alpha Vantage, Yahoo Finance, etc.)"""
        try:
            # Placeholder for alternative data sources
            self.logger.info(f"üîç Fetching {symbol} via alternative data sources...")
            
            # Try Alpha Vantage first
            if symbol in ["XAUUSD", "BTCUSD"]:
                return await self._fetch_alpha_vantage(symbol, timeframe, count)
            
            # Try Yahoo Finance as fallback
            return await self._fetch_yahoo_finance(symbol, timeframe, count)
            
        except Exception as e:
            self.logger.warning(f"Alternative API fetch cho {symbol} th·∫•t b·∫°i: {e}")
            return None
    
    async def _fetch_alpha_vantage(self, symbol: str, timeframe: str, count: int = 500) -> Optional[pd.DataFrame]:
        """Fetch data from Alpha Vantage for crypto/gold"""
        try:
            # Map symbols to Alpha Vantage format
            av_symbol_mapping = {
                "XAUUSD": "XAU",
                "BTCUSD": "BTC"
            }
            
            av_symbol = av_symbol_mapping.get(symbol)
            if not av_symbol:
                return None
            
            # Map timeframe
            tf_mapping = {"D1": "DAILY", "H4": "1_HOUR"}
            if timeframe not in tf_mapping:
                self.logger.warning(f"Timeframe {timeframe} not supported by Alpha Vantage")
                return None
            
            url = f"https://www.alphavantage.co/query"
            params = {
                'function': 'TIME_SERIES_' + tf_mapping[timeframe],
                'symbol': av_symbol,
                'apikey': Config.ALPHA_VANTAGE_API_KEY,  # Need to add this to config
                'outputsize': 'compact'  # Last 100 data points
            }
            
            self.logger.info(f"Fetching {symbol} ({av_symbol}) t·ª´ Alpha Vantage...")
            data = await self.api_manager._make_request(url, params=params, api_name='alpha_vantage')
            
            # Process Alpha Vantage response format
            if data and 'Time Series (Daily)' in data:
                df = self._process_alpha_vantage_data(data['Time Series (Daily)'])
                if not df.empty:
                    cache_key = f"{symbol}_{timeframe}"
                    self.data_cache[cache_key] = df
                    self.logger.info(f"‚úÖ ƒê√£ l·∫•y {len(df)} candles cho {symbol} t·ª´ Alpha Vantage")
                    return df
            
            return None
            
        except Exception as e:
            self.logger.warning(f"Alpha Vantage fetch th·∫•t b·∫°i cho {symbol}: {e}")
            return None
    
    async def _fetch_yahoo_finance(self, symbol: str, timeframe: str, count: int = 500) -> Optional[pd.DataFrame]:
        """Fetch data from Yahoo Finance (free fallback)"""
        try:
            # Yahoo Finance doesn't require API key but has rate limits
            self.logger.info(f"Fetching {symbol} t·ª´ Yahoo Finance (simulation)...")
            
            # This is a placeholder - would need actual Yahoo Finance integration
            symbols = ["XAUUSD", "EURUSD", "NAS100", "BTCUSD"]
            if symbol in symbols:
                # Create mock data for demonstration
                now = pd.Timestamp.now()
                mock_data = []
                
                for i in range(min(count, 100)):
                    timestamp = now - pd.Timedelta(hours=i)
                    base_price = {"XAUUSD": 2000, "EURUSD": 1.1, "NAS100": 15000, "BTCUSD": 65000}.get(symbol, 100)
                    price_noise = np.random.normal(0, base_price * 0.01)
                    
                    mock_data.append({
                        'timestamp': timestamp,
                        'open': base_price + price_noise,
                        'high': base_price + price_noise + abs(np.random.normal(0, base_price * 0.005)),
                        'low': base_price + price_noise - abs(np.random.normal(0, base_price * 0.005)),
                        'close': base_price + price_noise + np.random.normal(0, base_price * 0.002)
                    })
                
                df = pd.DataFrame(mock_data[::-1])  # Reverse to chronological order
                cache_key = f"{symbol}_{timeframe}"
                self.data_cache[cache_key] = df
                self.logger.info(f"‚úÖ Mock data created cho {symbol}: {len(df)} candles")
                return df
            
            return None
            
        except Exception as e:
            self.logger.warning(f"Yahoo Finance fetch th·∫•t b·∫°i cho {symbol}: {e}")
            return None
    
    def _process_alpha_vantage_data(self, data: dict) -> pd.DataFrame:
        """Process Alpha Vantage time series data"""
        rows = []
        for date, values in data.items():
            rows.append({
                'timestamp': pd.to_datetime(date),
                'open': float(values['1. open']),
                'high': float(values['2. high']),
                'low': float(values['3. low']),
                'close': float(values['4. close'])
            })
        
        df = pd.DataFrame(rows)
        return df.sort_values('timestamp').reset_index(drop=True)
    
    def _process_oanda_data(self, candles: List[Dict]) -> pd.DataFrame:
        """X·ª≠ l√Ω d·ªØ li·ªáu candles t·ª´ OANDA"""
        data = []
        
        for candle in candles:
            if candle['complete']:
                row = {
                    'timestamp': pd.to_datetime(candle['time']),
                    'open': float(candle['mid']['o']),
                    'high': float(candle['mid']['h']),
                    'low': float(candle['mid']['l']),
                    'close': float(candle['mid']['c']),
                    'volume': int(candle['volume'])
                }
                data.append(row)
        
        df = pd.DataFrame(data)
        df.set_index('timestamp', inplace=True)
        df.sort_index(inplace=True)
        
        return df
    
    async def get_fresh_data(self, symbol: str, timeframe: str) -> Optional[pd.DataFrame]:
        """L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t (t·ª± ƒë·ªông l√†m m·ªõi n·∫øu c·∫ßn)"""
        cache_key = f"{symbol}_{timeframe}"
        
        # Ki·ªÉm tra cache
        if cache_key in self.data_cache:
            if not self.freshness_manager.refresh_needed(symbol, timeframe):
                return self.data_cache[cache_key]
        
        # Fetch fresh data
        return await self.fetch_market_data(symbol, timeframe)
    
    def get_features(self, symbol: str, timeframe: str = 'H1') -> Optional[np.ndarray]:
        """Extract features for RL Agent from cached data"""
        try:
            cache_key = f"{symbol}_{timeframe}"
            
            if cache_key not in self.data_cache:
                self.logger.warning(f"No cached data available for {symbol} {timeframe}")
                return None
            
            df = self.data_cache[cache_key]
            
            if df.empty or len(df) < 10:
                self.logger.warning(f"Insufficient data for {symbol}: {len(df)} candles")
                return None
            
            # Extract basic OHLC features
            features = []
            
            # Recent OHLC data (relative to recent close)
            recent_close = df['close'].iloc[-1]
            
            # Normalize OHLC features
            features.extend([
                df['open'].iloc[-1] / recent_close - 1.0,   # open_norm
                df['high'].iloc[-1] / recent_close - 1.0,   # high_norm  
                df['low'].iloc[-1] / recent_close - 1.0,    # low_norm
                df['close'].iloc[-1] / recent_close - 1.0,  # close_norm (should be 0.0)
            ])
            
            # Volume feature (if available)
            if 'volume' in df.columns:
                volume_norm = df['volume'].iloc[-1] / df['volume'].rolling(10).mean().iloc[-1]
                features.append(volume_norm - 1.0)
            else:
                features.append(0.0)  # Default volume feature
            
            # Price momentum features
            for window in [5, 10]:
                if len(df) >= window:
                    momentum = (df['close'].iloc[-1] / df['close'].iloc[-window] - 1.0)
                    features.append(momentum)
                else:
                    features.append(0.0)
            
            # Volatility features
            if len(df) >= 10:
                returns = df['close'].pct_change().dropna()
                volatility = returns.tail(10).std()
                features.append(volatility)
            else:
                features.append(0.0)
            
            # High-Low spread feature
            price_spread = (df['high'].iloc[-1] - df['low'].iloc[-1]) / recent_close
            features.append(price_spread)
            
            # Convert to numpy array and clip extreme values
            feature_array = np.array(features, dtype=np.float32)
            feature_array = np.clip(feature_array, -1.0, 1.0)  # Clip to [-1, 1] range
            
            self.logger.debug(f"Extracted {len(feature_array)} features for {symbol}")
            return feature_array
            
        except Exception as e:
            self.logger.error(f"Error extracting features for {symbol}: {e}")
            return self._get_default_features()
    
    def _get_default_features(self) -> np.ndarray:
        """Return default feature array when extraction fails"""
        return np.array([0.0] * 10, dtype=np.float32)

# ===== ENGINEERING ƒê·∫∂C TR∆ØNG N√ÇNG CAO =====
class AdvancedFeatureEngineer:
    """X√¢y d·ª±ng ƒë·∫∑c tr∆∞ng k·ªπ thu·∫≠t n√¢ng cao v√† ML"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('FeatureEngineer')
    
    def engineer_all_features(self, df: pd.DataFrame, symbol: str = "") -> pd.DataFrame:
        """T√≠nh to√°n t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng cho DataFrame"""
        
        if df.empty:
            self.logger.warning("DataFrame r·ªóng, kh√¥ng th·ªÉ t√≠nh to√°n features")
            return df
        
        # Sao ch√©p DataFrame ƒë·ªÉ kh√¥ng thay ƒë·ªïi g·ªëc
        features_df = df.copy()
        
        try:
            # Normalize column names for feature engineering - handle timeframe suffixes
            features_df = self._normalize_column_names(features_df)
            
            # 1. C√°c ch·ªâ b√°o c∆° b·∫£n
            features_df = self._add_basic_indicators(features_df)
            
            # 2. ƒê·∫∑c tr∆∞ng th·ªëng k√™
            features_df = self._add_statistical_features(features_df)
            
            # 3. M√¥ h√¨nh n·∫øn
            features_df = self._add_candlestick_patterns(features_df)
            
            # 4. C·∫•u tr√∫c th·ªã tr∆∞·ªùng
            features_df = self._add_market_structure_features(features_df)
            
            # 5. ƒê·∫∑c tr∆∞ng Wyckoff
            features_df = self._add_wyckoff_features(features_df)
            
            # 6. Supply/Demand zones
            features_df = self._add_supply_demand_features(features_df)
            
            # 7. RSI Divergence
            features_df = self._add_rsi_divergence(features_df)
            
            # 8. Market Regime detection
            features_df = self._add_market_regime(features_df)
            
            self.logger.info(f"ƒê√£ t√≠nh to√°n {len(features_df.columns)} features cho {symbol}")
            
        except Exception as e:
            self.logger.error(f"L·ªói khi t√≠nh to√°n features: {e}")
        
        return features_df
    
    def _normalize_column_names(self, df: pd.DataFrame) -> pd.DataFrame:
        """Normalize column names for feature engineering"""
        
        # Check if we have standard OHLCV columns
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        has_m15_timeframe = False
        has_standard_columns = all(col in df.columns for col in required_columns)
        
        # If we don't have standard columns, try to extract from timeframe-suffixed columns
        if not has_standard_columns:
            # Priority order: M15 > H1 > H4 > D1
            timeframes = ['M15', 'H1', 'H4', 'D1']
            
            for tf in timeframes:
                col_mapping = {}
                for col in required_columns:
                    suffixed_col = f"{col}_{tf}"
                    if suffixed_col in df.columns:
                        col_mapping[suffixed_col] = col
                
                if len(col_mapping) >= 4:  # At least open, high, low, close
                    df_normalized = df.copy()
                    df_normalized = df_normalized.rename(columns=col_mapping)
                    
                    # If volume is missing, create a placeholder
                    if 'volume' not in df_normalized.columns:
                        df_normalized['volume'] = (df_normalized['high'] + df_normalized['low']) / 2
                    
                    # Keep original datetime column
                    df_normalized['datetime'] = df['datetime']
                    return df_normalized
        
        # If we already have standard columns, return as-is
        return df
    
    def _add_basic_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Th√™m c√°c ch·ªâ b√°o k·ªπ thu·∫≠t c∆° b·∫£n"""
        
        # ATR (Average True Range)
        df['atr'] = AverageTrueRange(high=df['high'], low=df['low'], close=df['close']).average_true_range()
        
        # ADX (Average Directional Index)
        adx_indicator = ADXIndicator(high=df['high'], low=df['low'], close=df['close'])
        df['adx'] = adx_indicator.adx()
        df['adx_pos'] = adx_indicator.adx_pos()
        df['adx_neg'] = adx_indicator.adx_neg()
        
        # RSI
        df['rsi'] = RSIIndicator(close=df['close']).rsi()
        
        # Pivot Points
        df['pivot'] = (df['high'] + df['low'] + df['close']) / 3
        df['resistance_1'] = 2 * df['pivot'] - df['low']
        df['support_1'] = 2 * df['pivot'] - df['high']
        df['resistance_2'] = df['pivot'] + (df['high'] - df['low'])
        df['support_2'] = df['pivot'] - (df['high'] - df['low'])
        
        return df
    
    def _add_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Th√™m c√°c ƒë·∫∑c tr∆∞ng th·ªëng k√™"""
        
        # Rolling returns
        for window in [5, 10, 20]:
            df[f'returns_{window}'] = df['close'].pct_change(window)
            df[f'returns_{window}_std'] = df[f'returns_{window}'].rolling(window).std()
        
        # Price volatility
        df['volatility'] = df['close'].rolling(20).std()
        df['volatility_ratio'] = df['volatility'] / df['volatility'].rolling(50).mean()
        
        # Statistical moments
        df['skew'] = df['close'].rolling(20).skew()
        df['kurtosis'] = df['close'].rolling(20).kurt()
        
        # Moving averages
        for ma_period in [5, 10, 20, 50, 200]:
            df[f'sma_{ma_period}'] = df['close'].rolling(ma_period).mean()
            df[f'price_vs_sma_{ma_period}'] = df['close'] / df[f'sma_{ma_period}'] - 1
        
        return df
    
    def _add_candlestick_patterns(self, df: pd.DataFrame) -> pd.DataFrame:
        """Th√™m c√°c m√¥ h√¨nh n·∫øn Nh·∫≠t"""
        
        # Body v√† Shadow sizes
        df['body_size'] = abs(df['close'] - df['open'])
        df['upper_shadow'] = df['high'] - df[['open', 'close']].max(axis=1)
        df['lower_shadow'] = df[['open', 'close']].min(axis=1) - df['low']
        
        # Doji pattern
        df['doji'] = (df['body_size'] / (df['high'] - df['low']) < 0.1).astype(int)
        
        # Hammer pattern
        hammer_conditions = (
            (df['lower_shadow'] > 2 * df['body_size']) &
            (df['upper_shadow'] < df['body_size']) &
            (df['close'] > df['open'])
        )
        df['hammer'] = hammer_conditions.astype(int)
        
        # Bullish/Bearish Engulfing
        df['bull_engulf'] = (
            (df['close'].shift(1) < df['open'].shift(1)) &
            (df['close'] > df['open']) &
            (df['open'] <= df['close'].shift(1)) &
            (df['close'] >= df['open'].shift(1))
        ).astype(int)
        
        df['bear_engulf'] = (
            (df['close'].shift(1) > df['open'].shift(1)) &
            (df['close'] < df['open']) &
            (df['open'] >= df['close'].shift(1)) &
            (df['close'] <= df['open'].shift(1))
        ).astype(int)
        
        return df
    
    def _add_market_structure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Th√™m ƒë·∫∑c tr∆∞ng c·∫•u tr√∫c th·ªã tr∆∞·ªùng"""
        
        # Higher highs / Lower lows
        df['hh'] = (df['high'] > df['high'].rolling(5).max().shift(1)).astype(int)
        df['lh'] = (df['high'] < df['high'].rolling(5).max().shift(1)).astype(int)
        df['hl'] = (df['low'] > df['low'].rolling(5).min().shift(1)).astype(int)
        df['ll'] = (df['low'] < df['low'].rolling(5).min().shift(1)).astype(int)
        
        # Swing points
        df['swing_high'] = (df['high'] >= df['high'].rolling(5).max()).astype(int)
        df['swing_low'] = (df['low'] <= df['low'].rolling(5).min()).astype(int)
        
        return df
    
    def _add_wyckoff_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Th√™m c√°c ƒë·∫∑c tr∆∞ng Wyckoff"""
        
        # Spring signal (gi√° ph√° th·∫•p nh∆∞ng ƒë√≥ng l·∫°i cao)
        df['spring'] = (
            (df['low'] < df['low'].rolling(20).min().shift(1)) &
            (df['close'] > df['open']) &
            (df['volume'] > df['volume'].rolling(20).mean())
        ).astype(int)
        
        # Upthrust signal (gi√° ph√° cao nh∆∞ng ƒë√≥ng l·∫°i th·∫•p)
        df['upthrust'] = (
            (df['high'] > df['high'].rolling(20).max().shift(1)) &
            (df['close'] < df['open']) &
            (df['volume'] > df['volume'].rolling(20).mean())
        ).astype(int)
        
        # Accumulation/Distribution phases
        # Simplified implementation
        price_momentum = df['close'].diff(10)
        volume_momentum = df['volume'].diff(10)
        
        df['accumulation'] = ((price_momentum < 0) & (volume_momentum > 0)).astype(int)
        df['distribution'] = ((price_momentum > 0) & (volume_momentum > 0)).astype(int)
        
        return df
    
    def _add_supply_demand_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Th√™m c√°c ƒë·∫∑c tr∆∞ng Supply/Demand zones"""
        
        # T√¨m c√°c v√πng Supply (kh√°ng c·ª±) v√† Demand (h·ªó tr·ª£)
        lookback = 20
        
        # Supply zones: c√°c ƒë·ªânh v·ªõi rejection
        supply_zones = []
        for i in range(lookback, len(df)):
            window_high = df['high'].iloc[i-lookback:i].max()
            current_high = df['high'].iloc[i]
            
            if current_high == window_high:
                # Ki·ªÉm tra rejection t·ª´ v√πng n√†y
                rejected = (
                    df['close'].iloc[i] < window_high * 0.995 and
                    df['volume'].iloc[i] > df['volume'].iloc[i-lookback:i].mean()
                )
                if rejected:
                    supply_zones.append(i)
        
        # Demand zones: c√°c ƒë√°y v·ªõi bounce
        demand_zones = []
        for i in range(lookback, len(df)):
            window_low = df['low'].iloc[i-lookback:i].min()
            current_low = df['low'].iloc[i]
            
            if current_low == window_low:
                # Ki·ªÉm tra bounce t·ª´ v√πng n√†y
                bounced = (
                    df['close'].iloc[i] > window_low * 1.005 and
                    df['volume'].iloc[i] > df['volume'].iloc[i-lookback:i].mean()
                )
                if bounced:
                    demand_zones.append(i)
        
        # T√≠nh kho·∫£ng c√°ch t·ª´ gi√° hi·ªán t·∫°i ƒë·∫øn c√°c zone g·∫ßn nh·∫•t
        df['distance_to_nearest_supply'] = float('inf')
        df['distance_to_nearest_demand'] = float('inf')
        
        for zone_idx in supply_zones:
            zone_price = df['high'].iloc[zone_idx]
            distance = np.abs(df['close'] - zone_price) / df['close'] * 100
            df['distance_to_nearest_supply'] = np.minimum(
                df['distance_to_nearest_supply'], distance
            )
        
        for zone_idx in demand_zones:
            zone_price = df['low'].iloc[zone_idx]
            distance = np.abs(df['close'] - zone_price) / df['close'] * 100
            df['distance_to_nearest_demand'] = np.minimum(
                df['distance_to_nearest_demand'], distance
            )
        
        return df
    
    def _add_rsi_divergence(self, df: pd.DataFrame) -> pd.DataFrame:
        """Ph√°t hi·ªán RSI Divergence"""
        
        df['bullish_rsi_div'] = 0
        df['bearish_rsi_div'] = 0
        
        # T√¨m c√°c swing highs v√† lows
        for i in range(5, len(df) - 5):
            # Bullish divergence: gi√° t·∫°o lower low nh∆∞ng RSI t·∫°o higher low
            if (df['low'].iloc[i] < df['low'].iloc[i-5:i].min() and
                df['low'].iloc[i+5:i+10].max() < df['low'].iloc[i] and
                df['rsi'].iloc[i] > df['rsi'].iloc[i-5:i].mean()):
                df['bullish_rsi_div'].iloc[i] = 1
            
            # Bearish divergence: gi√° t·∫°o higher high nh∆∞ng RSI t·∫°o lower high
            if (df['high'].iloc[i] > df['high'].iloc[i-5:i].max() and
                df['high'].iloc[i+5:i+10].min() > df['high'].iloc[i] and
                df['rsi'].iloc[i] < df['rsi'].iloc[i-5:i].mean()):
                df['bearish_rsi_div'].iloc[i] = 1
        
        return df
    
    def _add_market_regime(self, df: pd.DataFrame) -> pd.DataFrame:
        """Ph√¢n lo·∫°i market regime: Trending vs Sideways"""
        
        # T√≠nh ADX ƒë·ªÉ x√°c ƒë·ªãnh xu h∆∞·ªõng
        adx_value = df['adx'].fillna(0)
        
        # T√≠nh slope c·ªßa moving average ƒë·ªÉ x√°c ƒë·ªãnh direction
        ma_slope = df['sma_20'].diff(5) / df['sma_20'].shift(5) * 100
        
        # X√°c ƒë·ªãnh regime
        conditions = [
            (adx_value > 25) & (ma_slope > 0.1),  # Uptrend
            (adx_value > 25) & (ma_slope < -0.1),  # Downtrend
            adx_value <= 25  # Sideways
        ]
        
        choices = ['uptrend', 'downtrend', 'sideways']
        df['market_regime'] = np.select(conditions, choices, default='sideways')
        
        return df

# ===== QU·∫¢N L√ù TIN T·ª®C V√Ä SENTIMENT ANALYSIS =====
class GeminiSentimentAnalyzer:
    """Ph√¢n t√≠ch sentiment b·∫±ng Gemini AI"""
    
    def __init__(self, api_manager: APIManager):
        self.api_manager = api_manager
        self.logger = LOG_MANAGER.get_logger('NewsManager')
        
    async def analyze_sentiment(self, text: str) -> float:
        """Ph√¢n t√≠ch sentiment c·ªßa text, tr·∫£ v·ªÅ score t·ª´ -1.0 ƒë·∫øn 1.0"""
        
        try:
            prompt = f"""
            Analyze the sentiment of this trading/financial news text and respond with only a number between -1.0 (very negative) and 1.0 (very positive):
            
            Text: {text[:500]}
            
            Consider:
            - Market impact (positive=higher prices, negative=lower prices)
            - Economic implications
            - Investor confidence
            - Company/financial performance
            
            Respond with only the sentiment score number:
            """
            
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={Config.GEMINI_API_KEY}"
            
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.1,
                    "maxOutputTokens": 10
                }
            }
            
            headers = {
                'Content-Type': 'application/json'
            }
            
            # Fallback n·∫øu Gemini kh√¥ng kh·∫£ d·ª•ng
            sentiment_score = self._simple_sentiment_fallback(text)
            return sentiment_score
            
        except Exception as e:
            self.logger.warning(f"L·ªói Gemini sentiment analysis: {e}, d√πng fallback")
            return self._simple_sentiment_fallback(text)
    
    def _simple_sentiment_fallback(self, text: str) -> float:
        """Simple sentiment analysis fallback"""
        
        positive_words = [
            'bull', 'bullish', 'rise', 'gain', 'increase', 'up', 'positive', 
            'growth', 'strong', 'robust', 'surge', 'rally', 'optimism',
            'beat', 'exceed', 'outperform', 'better', 'improve'
        ]
        
        negative_words = [
            'bear', 'bearish', 'fall', 'drop', 'decline', 'down', 'negative',
            'weak', 'poor', 'crash', 'plunge', 'pessimistic', 'concern',
            'miss', 'disappoint', 'worse', 'deteriorate'
        ]
        
        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        total_words = len(text.split())
        if total_words == 0:
            return 0.0
        
        pos_ratio = pos_count / total_words
        neg_ratio = neg_count / total_words
        
        score = pos_ratio - neg_ratio
        return np.clip(score * 5, -1.0, 1.0)  # Scale v√† clamp

class NewsEconomicManager:
    """Qu·∫£n l√Ω tin t·ª©c v√† l·ªãch kinh t·∫ø v·ªõi sentiment analysis"""
    
    def __init__(self, api_manager: APIManager):
        self.api_manager = api_manager
        self.sentiment_analyzer = GeminiSentimentAnalyzer(api_manager)
        self.logger = LOG_MANAGER.get_logger('NewsManager')
        self.news_cache = {}
    
    async def fetch_news_sentiment(self, symbol: str, hours_back: int = 24) -> Dict[str, Any]:
        """L·∫•y tin t·ª©c v√† ph√¢n t√≠ch sentiment"""
        
        news_data = {
            'sentiment_score': 0.0,
            'news_count': 0,
            'positive_news': 0,
            'negative_news': 0,
            'latest_news_items': []
        }
        
        try:
            # Fetch t·ª´ nhi·ªÅu ngu·ªìn song song
            tasks = []
            
            # Finnhub News
            if symbol in ['EURUSD', 'NAS100']:  # Forex/Index symbols
                tasks.append(self._fetch_finnhub_news(symbol))
            
            # MarketAux News
            tasks.append(self._fetch_marketaux_news(symbol))
            
            # NewsAPI News
            tasks.append(self._fetch_newsapi_news(symbol))
            
            # Ch·∫°y t·∫•t c·∫£ tasks song song
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            all_news = []
            for result in results:
                if isinstance(result, list):
                    # Handle MarketAux direct list results
                    for article in result:
                        # MarketAux structure: title, description  
                        title = article.get('title', '')
                        description = article.get('description', '')
                        if title or description:
                            all_news.append({'text': f"{title} {description}".strip()})
                elif isinstance(result, dict) and 'articles' in result:
                    # Handle NewsAPI structure
                    for article in result['articles']:
                        title = article.get('title', '')
                        description = article.get('description', '')
                        if title or description:
                            all_news.append({'text': f"{title} {description}".strip()})
                elif isinstance(result, dict):
                    # Handle FinnHub structure (headline, summary)
                    title = result.get('headline', '')
                    summary = result.get('summary', '')
                    if title or summary:
                        all_news.append({'text': f"{title} {summary}".strip()})
            
            # Ph√¢n t√≠ch sentiment cho m·ªói tin
            if all_news:
                sentiment_scores = []
                for news_item in all_news[:10]:  # Gi·ªõi h·∫°n 10 tin m·ªõi nh·∫•t
                    # Safely access text field with error handling
                    text = news_item.get('text', '')
                    if len(text.strip()) > 10:  # Ch·ªâ ph√¢n t√≠ch n·∫øu c√≥ ƒë·ªß text
                        sentiment = await self.sentiment_analyzer.analyze_sentiment(text)
                        sentiment_scores.append(sentiment)
                        news_data['latest_news_items'].append({
                            'text': text[:100] + '...',
                            'sentiment': sentiment
                        })
                
                if sentiment_scores:
                    # T√≠nh trung b√¨nh c√≥ tr·ªçng s·ªë
                    avg_sentiment = np.mean(sentiment_scores)
                    news_data['sentiment_score'] = avg_sentiment
                    news_data['news_count'] = len(sentiment_scores)
                    news_data['positive_news'] = sum(1 for s in sentiment_scores if s > 0)
                    news_data['negative_news'] = sum(1 for s in sentiment_scores if s < 0)
            
            self.logger.info(f"C√≥ {news_data['news_count']} tin t·ª©c cho {symbol}, sentiment: {news_data['sentiment_score']:.2f}")
            
        except Exception as e:
            self.logger.error(f"L·ªói khi fetch news cho {symbol}: {e}")
        
        return news_data
    
    async def _fetch_finnhub_news(self, symbol: str) -> List[Dict]:
        """Fetch news t·ª´ Finnhub - Skip FinnHub due to invalid API key for now"""
        # Skip FinnHub due to invalid API key (returns 401)
        # Return empty list to avoid crashes
        if Config.FINNHUB_API_KEY == "YOUR_VALID_FINNHUB_KEY_HERE":
            # Only log once per session to reduce noise
            if not hasattr(self, '_finnhub_warning_logged'):
                self.logger.warning("Skipping FinnHub news due to invalid API key (set FINNHUB_API_KEY in config)")
                self._finnhub_warning_logged = True
        return []
    
    async def _fetch_marketaux_news(self, symbol: str) -> List[Dict]:
        """Fetch news t·ª´ MarketAux"""
        url = "https://api.marketaux.com/v1/news/all"
        params = {
            'symbols': symbol,
            'sort': 'latest',
            'limit': 5,
            'api_token': Config.MARKETAUX_API_KEY
        }
        
        data = await self.api_manager._make_request(url, params=params, api_name='marketaux')
        if data and 'data' in data:
            return data['data']
        return []
    
    async def _fetch_newsapi_news(self, symbol: str) -> Dict:
        """Fetch news t·ª´ NewsAPI"""
        # Map symbol to search terms
        search_terms = {
            'XAUUSD': 'gold price',
            'EURUSD': 'euro dollar forex',
            'NAS100': 'NASDAQ nasdaq',
            'BTCUSD': 'bitcoin cryptocurrency'
        }
        
        search_term = search_terms.get(symbol, symbol)
        url = "https://newsapi.org/v2/everything"
        params = {
            'q': search_term,
            'sortBy': 'publishedAt',
            'pageSize': 5,
            'language': 'en',
            'apiKey': Config.NEWSAPI_API_KEY
        }
        
        try:
            data = await self.api_manager._make_request(url, params=params, api_name='newsapi')
            return data or {}
        except Exception as e:
            self.logger.warning(f"NewsAPI request failed: {e}")
            return {}
    
    async def fetch_economic_calendar(self, hours_ahead: int = 24) -> List[Dict]:
        """L·∫•y l·ªãch kinh t·∫ø"""
        # Simplified economic calendar
        # Trong th·ª±c t·∫ø s·∫Ω fetch t·ª´ c√°c API nh∆∞ ForexFactory, Investing.com
        
        economic_events = [
            {
                'time': datetime.now() + timedelta(hours=2),
                'event': 'Non-Farm Payrolls',
                'importance': 'high',
                'currency': 'USD',
                'forecast': '210K',
                'previous': '185K'
            },
            {
                'time': datetime.now() + timedelta(hours=8),
                'event': 'Consumer Price Index',
                'importance': 'medium',
                'currency': 'EUR',
                'forecast': '2.1%',
                'previous': '1.9%'
            }
        ]
        
        # Filter events trong timeframe
        upcoming_events = [
            event for event in economic_events 
            if event['time'] <= datetime.now() + timedelta(hours=hours_ahead)
        ]
        
        return upcoming_events

# Ti·∫øp t·ª•c v·ªõi c√°c ph·∫ßn ti·∫øp theo...

# ===== ENSEMBLE MODELS V√Ä OPTUNA OPTIMIZATION =====
class PurgedGroupTimeSeriesSplit:
    """Custom cross-validation cho time series v·ªõi gap ƒë·ªÉ tr√°nh data leakage"""
    
    def __init__(self, n_splits=5, gap=10):
        self.n_splits = n_splits
        self.gap = gap
    
    def split(self, X, y=None, groups=None):
        """Split data v·ªõi gap ƒë·ªÉ tr√°nh leakage"""
        n_samples = len(X)
        samples_per_split = n_samples // self.n_splits
        
        for i in range(self.n_splits):
            start = i * samples_per_split
            if i == self.n_splits - 1:
                end = n_samples
            else:
                end = (i + 1) * samples_per_split - self.gap
            
            if start >= end:
                continue
                
            train_indices = list(range(start, end))
            
            val_start = end + self.gap
            val_end = val_start + samples_per_split if i < self.n_splits - 1 else n_samples
            
            if val_start < n_samples:
                val_indices = list(range(val_start, val_end))
                yield train_indices, val_indices

class EnsembleModel:
    """Ensemble model v·ªõi AutoML v√† hyperparameter optimization"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('EnsembleModel')
        self.models = {}
        self.meta_model = None
        self.feature_importance = {}
        self.feature_names = None  # Store feature names used during training
        self.cv_scorer = sklearn.metrics.make_scorer(sklearn.metrics.accuracy_score)
        self.cv_splitter = PurgedGroupTimeSeriesSplit(n_splits=5, gap=10)
        
        # Models v·ªõi Optuna optimization - Updated for multi-class classification
        self.model_configs = {
            'xgboost': {
                'objective': 'multi:softmax',
                'eval_metric': 'mlogloss',
                'num_class': 3,  # 3 classes: 0=SELL, 1=BUY, 2=HOLD
                'seed': 42
            },
            'lightgbm': {
                'objective': 'multiclass',
                'metric': 'multi_logloss',
                'num_class': 3,  # 3 classes: 0=SELL, 1=BUY, 2=HOLD
                'random_seed': 42,
                'verbose': -1
            },
            'random_forest': {
                'random_state': 42,
                'n_jobs': -1
            }
        }
    
    def optimize_hyperparameters(self, X_train: pd.DataFrame, y_train: pd.Series, 
                               model_name: str) -> Dict[str, Any]:
        """T·ªëi ∆∞u h√≥a hyperparameters b·∫±ng Optuna"""
        
        def objective(trial):
            if model_name == 'xgboost':
                params = {
                    'max_depth': trial.suggest_int('max_depth', 3, 10),
                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                    'n_estimators': trial.suggest_int('n_estimators', 50, 1000),
                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                }
            elif model_name == 'lightgbm':
                params = {
                    'num_leaves': trial.suggest_int('num_leaves', 10, 100),
                    'max_depth': trial.suggest_int('max_depth', 3, 10),
                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                    'n_estimators': trial.suggest_int('n_estimators', 50, 1000),
                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                    'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
                    'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 50),
                    'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-3, 1.0),
                    'max_bin': trial.suggest_int('max_bin', 50, 255),
                    'force_col_wise': True,
                    'verbosity': -1
                }
            elif model_name == 'random_forest':
                params = {
                    'n_estimators': trial.suggest_int('n_estimators', 50, 500),
                    'max_depth': trial.suggest_int('max_depth', 3, 15),
                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2'])
                }
            
            # Train v√† evaluate model
            cv_scores = []
            for train_idx, val_idx in self.cv_splitter.split(X_train):
                X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]
                y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]
                
                if model_name == 'xgboost':
                    model = xgb.XGBClassifier(**params)
                elif model_name == 'lightgbm':
                    model = lgb.LGBMClassifier(**params)
                elif model_name == 'random_forest':
                    model = RandomForestClassifier(**params)
                
                model.fit(X_train_fold, y_train_fold)
                pred = model.predict(X_val_fold)
                score = accuracy_score(y_val_fold, pred)
                cv_scores.append(score)
            
            return np.mean(cv_scores)
        
        # Run optimization
        study = optuna.create_study(direction='maximize')
        study.optimize(objective, n_trials=100)
        
        self.logger.info(f"Best {model_name} params: {study.best_params}")
        return study.best_params
    
    def train_ensemble(self, X_train: pd.DataFrame, y_train: pd.Series) -> Dict[str, float]:
        """Hu·∫•n luy·ªán ensemble models v·ªõi optimized parameters"""
        
        try:
            # Validate input data
            if X_train.empty or y_train.empty:
                self.logger.error("Empty training data provided")
                return {'error': 'Empty training data'}
            
            if len(X_train) != len(y_train):
                self.logger.error(f"Feature and target length mismatch: {len(X_train)} vs {len(y_train)}")
                return {'error': 'Data length mismatch'}
            
            if len(X_train) < 10:
                self.logger.error(f"Insufficient training data: {len(X_train)} samples")
                return {'error': 'Insufficient training data'}
            
            # Store feature names for consistency during prediction
            self.feature_names = list(X_train.columns)
            self.logger.info(f"EnsembleModel storing feature names: {self.feature_names}")
            self.logger.info(f"Training ensemble with {len(X_train)} samples, {len(self.feature_names)} features")
            
            # Use default parameters instead of optimization for faster training
            optimized_params = {}
            for model_name in ['xgboost', 'lightgbm', 'random_forest']:
                try:
                    # Use default parameters for faster training
                    optimized_params[model_name] = self.model_configs[model_name]
                    self.logger.info(f"Using default parameters for {model_name}")
                except Exception as e:
                    self.logger.error(f"L·ªói getting parameters {model_name}: {e}")
                    optimized_params[model_name] = self.model_configs[model_name]
            
            # Train models v·ªõi optimized parameters - Updated for multi-class
            base_predictions = np.zeros((len(X_train), len(optimized_params) * 3))  # 3 classes per model
            
            for i, (model_name, params) in enumerate(optimized_params.items()):
                try:
                    self.logger.info(f"Training {model_name} model...")
                    if model_name == 'xgboost':
                        model = xgb.XGBClassifier(**params)
                    elif model_name == 'lightgbm':
                        model = lgb.LGBMClassifier(**params)
                    elif model_name == 'random_forest':
                        model = RandomForestClassifier(**params)
                    
                    # Train model
                    model.fit(X_train, y_train)
                    
                    # Get predictions for multi-class - store all class probabilities
                    pred_proba = model.predict_proba(X_train)
                    # For multi-class, we need to store probabilities for all classes
                    # Reshape to store 3 classes per model
                    base_predictions[:, i*3:(i+1)*3] = pred_proba
                    
                    # Store trained model
                    self.models[model_name] = model
                    self.logger.info(f"‚úÖ {model_name} model trained successfully")
                    
                except Exception as e:
                    self.logger.error(f"Failed to train {model_name}: {e}")
                    # Fill with uniform distribution if training fails
                    base_predictions[:, i*3:(i+1)*3] = np.full((len(X_train), 3), 1/3)
                    continue
                
                # Calibrate probabilities with error handling
                try:
                    calibrated_model = CalibratedClassifierCV(model, method='sigmoid', cv=3)
                    calibrated_model.fit(X_train, y_train)
                    
                    # Verify calibration was successful by checking if calibrated_classifiers_ exist
                    if not hasattr(calibrated_model, 'calibrated_classifiers_') or len(calibrated_model.calibrated_classifiers_) == 0:
                        raise ValueError("Calibration failed - no calibrated classifiers found")
                    
                    self.logger.info(f"S·ª≠ d·ª•ng calibrated model cho {model_name}")
                except Exception as calib_error:
                    self.logger.warning(f"Calibration failed for {model_name}: {calib_error}")
                    self.logger.info(f"S·ª≠ d·ª•ng model g·ªëc cho {model_name}")
                    # Fallback to original model
                    calibrated_model = model
                    calibrated_model.fit(X_train, y_train)
                
                self.models[model_name] = calibrated_model
                
                # Get predictions for meta-model - Updated for multi-class
                if hasattr(calibrated_model, 'predict_proba'):
                    predictions = calibrated_model.predict_proba(X_train)
                    # Store all class probabilities
                    base_predictions[:, i*3:(i+1)*3] = predictions
                else:
                    # Fallback for models without predict_proba
                    predictions = calibrated_model.predict(X_train)
                    # Convert to one-hot encoding
                    one_hot = np.zeros((len(predictions), 3))
                    for j, pred in enumerate(predictions):
                        if 0 <= pred < 3:  # Ensure valid class
                            one_hot[j, int(pred)] = 1.0
                        else:
                            one_hot[j, 2] = 1.0  # Default to HOLD
                    base_predictions[:, i*3:(i+1)*3] = one_hot
                
                # Calculate feature importance
                estimator_to_check = None
                if hasattr(calibrated_model, 'estimator_') and calibrated_model.estimator_ is not None:
                    estimator_to_check = calibrated_model.estimator_
                else:
                    estimator_to_check = calibrated_model
                
                if hasattr(estimator_to_check, 'feature_importances_'):
                    self.feature_importance[model_name] = estimator_to_check.feature_importances_
                
                self.logger.info(f"Ho√†n th√†nh training {model_name}")
        
            # Train meta-model (Logistic Regression)
            self.meta_model = LogisticRegression()
            self.meta_model.fit(base_predictions, y_train)
            
            self.logger.info("Ho√†n th√†nh ensemble training")
            return self._evaluate_performance(X_train, y_train)
            
        except Exception as e:
            self.logger.error(f"Ensemble training failed: {e}")
            return {'error': f'Training failed: {str(e)}'}
    
    def _evaluate_performance(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
        """ƒê√°nh gi√° performance c·ªßa ensemble"""
        
        cv_scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}
        
        for train_idx, val_idx in self.cv_splitter.split(X):
            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
            
            # Train ensemble on fold
            temp_ensemble = EnsembleModel()
            temp_ensemble.models = {}
            temp_ensemble.feature_names = self.feature_names  # Copy feature names
            
            base_predictions = np.zeros((len(X_train_fold), len(self.models)))
            
            for i, (name, model) in enumerate(self.models.items()):
                try:
                    # Create a fresh instance of the model for CV
                    if name == 'xgboost':
                        fresh_model = xgb.XGBClassifier(**self.model_configs[name])
                    elif name == 'lightgbm':
                        fresh_model = lgb.LGBMClassifier(**self.model_configs[name])
                    elif name == 'random_forest':
                        fresh_model = RandomForestClassifier(**self.model_configs[name])
                    
                    fresh_model.fit(X_train_fold, y_train_fold)
                    temp_ensemble.models[name] = fresh_model
                    
                    if hasattr(fresh_model, 'predict_proba'):
                        base_predictions[:, i] = fresh_model.predict_proba(X_train_fold)[:, 1]
                    else:
                        predictions = fresh_model.decision_function(X_train_fold)
                        scaler = MinMaxScaler()
                        predictions = scaler.fit_transform(predictions.reshape(-1, 1)).flatten()
                        base_predictions[:, i] = predictions
                except Exception as e:
                    self.logger.error(f"Error training {name} in CV fold: {e}")
                    base_predictions[:, i] = 0.5  # Default probability
            
            temp_meta = LogisticRegression()
            temp_meta.fit(base_predictions, y_train_fold)
            
            #Predict on validation set
            val_base_predictions = np.zeros((len(X_val_fold), len(temp_ensemble.models)))
            for i, (name, model) in enumerate(temp_ensemble.models.items()):
                try:
                    if hasattr(model, 'predict_proba'):
                        val_base_predictions[:, i] = model.predict_proba(X_val_fold)[:, 1]
                    else:
                        predictions = model.decision_function(X_val_fold)
                        scaler = MinMaxScaler()
                        predictions = scaler.fit_transform(predictions.reshape(-1, 1)).flatten()
                        val_base_predictions[:, i] = predictions
                except Exception as e:
                    self.logger.error(f"Error predicting with {name} in CV validation: {e}")
                    val_base_predictions[:, i] = 0.5  # Default probability
            
            val_predictions = temp_meta.predict(val_base_predictions)
            
            # Calculate metrics
            from sklearn.metrics import precision_score, recall_score, f1_score
            cv_scores['accuracy'].append(accuracy_score(y_val_fold, val_predictions))
            cv_scores['precision'].append(precision_score(y_val_fold, val_predictions, zero_division=0))
            cv_scores['recall'].append(recall_score(y_val_fold, val_predictions, zero_division=0))
            cv_scores['f1'].append(f1_score(y_val_fold, val_predictions, zero_division=0))
        
        # Calculate mean scores
        mean_scores = {metric: np.mean(scores) for metric, scores in cv_scores.items()}
        
        self.logger.info(f"Ensemble CV scores - Accuracy: {mean_scores['accuracy']:.3f}, "
                        f"F1: {mean_scores['f1']:.3f}")
        
        return mean_scores
    
    def predict(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """D·ª± ƒëo√°n v·ªõi ensemble"""
        
        # Ensure prediction features match training features
        try:
            X_normalized = self._normalize_prediction_features(X)
        except Exception as e:
            self.logger.warning(f"Feature normalization failed: {e}")
            return np.zeros(len(X)), np.ones(len(X)) * 0.5
        
        # Base model predictions - Updated for multi-class
        # For multi-class, we need to store probabilities for each class
        base_predictions = np.zeros((len(X_normalized), len(self.models) * 3))  # 3 classes per model
        
        for i, (name, model) in enumerate(self.models.items()):
            try:
                if hasattr(model, 'predict_proba'):
                    # Get probabilities for all 3 classes
                    class_probs = model.predict_proba(X_normalized)
                    # Store probabilities for each class
                    base_predictions[:, i*3:(i+1)*3] = class_probs
                else:
                    # Fallback for models without predict_proba
                    predictions = model.predict(X_normalized)
                    # Convert to one-hot encoding
                    one_hot = np.zeros((len(predictions), 3))
                    for j, pred in enumerate(predictions):
                        if 0 <= pred < 3:  # Ensure valid class
                            one_hot[j, int(pred)] = 1.0
                        else:
                            one_hot[j, 2] = 1.0  # Default to HOLD
                    base_predictions[:, i*3:(i+1)*3] = one_hot
            except Exception as e:
                self.logger.error(f"Error predicting with {name}: {e}")
                # Use uniform distribution as fallback
                base_predictions[:, i*3:(i+1)*3] = np.full((len(X_normalized), 3), 1/3)
        
        # Meta-model prediction
        meta_predictions = self.meta_model.predict_proba(base_predictions)
        
        # Return predicted class and confidence (max probability)
        predicted_classes = np.argmax(meta_predictions, axis=1)
        confidence_scores = np.max(meta_predictions, axis=1)
        
        return predicted_classes, confidence_scores
    
    def _normalize_prediction_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """Normalize prediction features to match training features"""
        
        # Use stored feature names from training
        if self.feature_names is None:
            self.logger.warning("No training feature names stored, using current features")
            return X
        
        # Check if we have the same features as during training
        current_features = set(X.columns)
        training_features = set(self.feature_names)
        
        if current_features != training_features:
            # Only log detailed mismatch info in debug mode to reduce noise
            if len(current_features) > len(training_features) * 2:  # Significant mismatch
                self.logger.warning(f"Feature mismatch detected! Training: {len(training_features)} features, Prediction: {len(current_features)} features")
            
            # Add missing features with default values
            missing_features = training_features - current_features
            if missing_features:
                for feature in missing_features:
                    X[feature] = 0.0
            
            # Remove extra features (keep only training features)
            extra_features = current_features - training_features
            if extra_features:
                X = X.drop(columns=list(extra_features))
            
            # Reorder columns to match training order
            X = X[self.feature_names]
        
        return X

# ===== LSTM MODEL V·ªöI ATTENTION =====
class LSTMModel:
    """LSTM Model v·ªõi Attention mechanism"""
    
    def __init__(self, sequence_length: int = 50, feature_dim: int = None):
        self.sequence_length = sequence_length
        self.feature_dim = feature_dim  # Will be determined from data
        self.model = None
        self.logger = LOG_MANAGER.get_logger('EnsembleModel')
        self.is_trained = False
        self.scaler = None
        self.feature_names = None  # Store feature names used during training
    
    def _build_model(self):
        """X√¢y d·ª±ng ki·∫øn tr√∫c LSTM v·ªõi Attention"""
        
        if self.feature_dim is None:
            raise ValueError("Feature dimension must be set before building model")
        
        # Input layer
        inputs = Input(shape=(self.sequence_length, self.feature_dim), name='input_sequences')
        
        # First LSTM layer with dropout
        lstm1 = LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inputs)
        
        # Attention mechanism
        attention = tf.keras.layers.MultiHeadAttention(
            num_heads=8, 
            key_dim=128,
            dropout=0.1
        )(lstm1, lstm1)
        
        # Batch normalization after attention
        attention_bn = BatchNormalization()(attention)
        
        # Second LSTM layer
        lstm2 = LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(attention_bn)
        lstm2_bn = BatchNormalization()(lstm2)
        
        # Dense layers
        dense1 = Dense(64, activation='relu')(lstm2_bn)
        dense1_drop = Dropout(0.3)(dense1)
        
        dense2 = Dense(32, activation='relu')(dense1_drop)
        dense2_drop = Dropout(0.2)(dense2)
        
        # Output layer - 3 classes: 0=SELL, 1=BUY, 2=HOLD
        output = Dense(3, activation='softmax', name='prediction')(dense2_drop)
        
        # Create model
        self.model = Model(inputs=inputs, outputs=output)
        
        # Compile model
        optimizer = Adam(learning_rate=0.001, clipnorm=1.0)
        self.model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.logger.info("ƒê√£ x√¢y d·ª±ng ki·∫øn tr√∫c LSTM v·ªõi Attention")
    
    def prepare_sequences(self, X: pd.DataFrame, y: pd.Series) -> Tuple[np.ndarray, np.ndarray]:
        """Chu·∫©n b·ªã data th√†nh sequences cho LSTM"""
        
        # Store feature names for consistency during prediction
        self.feature_names = list(X.columns)
        self.logger.info(f"LSTM storing feature names: {self.feature_names}")
        
        # Determine feature dimension from data if not set
        if self.feature_dim is None:
            self.feature_dim = X.shape[1]
            self.logger.info(f"LSTM feature dimension set to {self.feature_dim}")
            # Rebuild model with correct feature dimension
            self._build_model()
        elif self.feature_dim != X.shape[1]:
            # Feature dimension has changed, update it and rebuild model
            old_dim = self.feature_dim
            self.feature_dim = X.shape[1]
            self.logger.info(f"LSTM feature dimension changed from {old_dim} to {self.feature_dim}, rebuilding model")
            self._build_model()
        
        # Scale features
        scaler = sklearn.preprocessing.StandardScaler()
        X_scaled = scaler.fit_transform(X)
        self.scaler = scaler
        # Store feature names for scaler consistency
        self.scaler_feature_names = list(X.columns)
        
        # Ensure y has the same length as X_scaled after scaling
        if len(y) != len(X_scaled):
            self.logger.warning(f"Target length ({len(y)}) doesn't match feature length ({len(X_scaled)})")
            min_len = min(len(y), len(X_scaled))
            X_scaled = X_scaled[:min_len]
            y = y[:min_len]
        
        # Create sequences
        X_sequences = []
        y_sequences = []
        
        for i in range(self.sequence_length, len(X_scaled)):
            X_sequences.append(X_scaled[i-self.sequence_length:i])
            y_sequences.append(y.iloc[i])
        
        # Convert to numpy arrays
        X_array = np.array(X_sequences)
        y_array = np.array(y_sequences)
        
        # Ensure targets are properly shaped for binary classification
        if y_array.ndim == 1:
            y_array = y_array.reshape(-1, 1)
        
        return X_array, y_array
    
    def train(self, X: pd.DataFrame, y: pd.Series, 
              validation_split: float = 0.2, epochs: int = 100) -> Dict[str, float]:
        """Hu·∫•n luy·ªán LSTM model"""
        
        try:
            # Validate input data
            if X.empty or y.empty:
                self.logger.error("Empty training data provided to LSTM")
                return {'error': 'Empty training data'}
            
            if len(X) != len(y):
                self.logger.error(f"LSTM feature and target length mismatch: {len(X)} vs {len(y)}")
                return {'error': 'Data length mismatch'}
            
            if len(X) < self.sequence_length + 10:
                self.logger.error(f"Insufficient training data for LSTM: {len(X)} samples (need at least {self.sequence_length + 10})")
                return {'error': 'Insufficient training data'}
            
            self.logger.info(f"LSTM training with {len(X)} samples, {X.shape[1]} features")
            
            # Prepare sequences
            X_seq, y_seq = self.prepare_sequences(X, y)
            
            # Validate sequences
            if len(X_seq) == 0:
                self.logger.error("No sequences created from input data")
                return {'error': 'Insufficient data for training'}
            
            if X_seq.shape[1] != self.sequence_length:
                self.logger.error(f"Sequence length mismatch: expected {self.sequence_length}, got {X_seq.shape[1]}")
                return {'error': 'Data preprocessing error'}
            
            # Validate tensor shapes
            self.logger.info(f"Training data shapes: X_seq={X_seq.shape}, y_seq={y_seq.shape}")
            
            # Ensure y_seq has proper shape for binary classification
            if y_seq.shape != (X_seq.shape[0], 1):
                self.logger.warning(f"Reshaping y_seq from {y_seq.shape} to ({X_seq.shape[0]}, 1)")
                y_seq = y_seq.reshape(X_seq.shape[0], 1)
            
            # Split data
            split_idx = int(len(X_seq) * (1 - validation_split))
            X_train_seq, X_val_seq = X_seq[:split_idx], X_seq[split_idx:]
            y_train_seq, y_val_seq = y_seq[:split_idx], y_seq[split_idx:]
            
            self.logger.info(f"Split data: train={len(X_train_seq)}, val={len(X_val_seq)}")
            
            # Callbacks
            early_stopping = EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True,
                verbose=1
            )
            
            reduce_lr = ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=10,
                min_lr=1e-7,
                verbose=1
            )
            
            # Train model
            try:
                self.logger.info("Starting LSTM model training...")
                history = self.model.fit(
                    X_train_seq, y_train_seq,
                    validation_data=(X_val_seq, y_val_seq),
                    epochs=epochs,
                    batch_size=32,
                    callbacks=[early_stopping, reduce_lr],
                    verbose=1
                )
                self.logger.info("‚úÖ LSTM model training completed")
            except Exception as e:
                self.logger.error(f"Model training error: {e}")
                return {'error': f'Training failed: {str(e)}'}
            
            self.is_trained = True
            
            # Evaluate
            try:
                val_loss, val_acc, val_prec, val_rec = self.model.evaluate(X_val_seq, y_val_seq, verbose=0)
                
                self.logger.info(f"LSTM Training completed - Val Acc: {val_acc:.3f}, Val Loss: {val_loss:.3f}")
                
                return {
                    'training_completed': True,
                    'val_accuracy': val_acc,
                    'val_loss': val_loss,
                    'val_precision': val_prec,
                    'val_recall': val_rec
                }
            except Exception as e:
                self.logger.warning(f"Evaluation failed: {e}")
                return {'training_completed': True, 'evaluation_failed': str(e)}
                
        except Exception as e:
            self.logger.error(f"LSTM training failed: {e}")
            return {'error': f'Training failed: {str(e)}'}
    
    def predict(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """D·ª± ƒëo√°n v·ªõi LSTM model"""
        
        if not self.is_trained:
            self.logger.warning("LSTM model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán")
            return np.zeros(len(X)), np.zeros(len(X))
        
        # Ensure feature consistency with training data
        X = self.ensure_feature_consistency(X)
        
        # Prepare sequences - ensure X has the same column order as during training
        if hasattr(self, 'scaler_feature_names'):
            X = X[self.scaler_feature_names]
        X_scaled = self.scaler.transform(X)
        X_sequences = []
        
        for i in range(self.sequence_length, len(X_scaled)):
            X_sequences.append(X_scaled[i-self.sequence_length:i])
        
        if not X_sequences:
            return np.zeros(len(X)), np.zeros(len(X))
        
        X_seq = np.array(X_sequences)
        
        # Predict - get probabilities for 3 classes
        class_probabilities = self.model.predict(X_seq, verbose=0)
        
        # Get predicted class (argmax) and confidence (max probability)
        predictions = np.argmax(class_probabilities, axis=1)
        probabilities = np.max(class_probabilities, axis=1)
        
        # Pad v·ªõi zeros cho c√°c ƒëi·ªÉm ƒë·∫ßu
        full_predictions = np.zeros(len(X))
        full_probabilities = np.zeros(len(X))
        
        full_predictions[self.sequence_length:] = predictions
        full_probabilities[self.sequence_length:] = probabilities
        
        return full_predictions, full_probabilities
    
    def ensure_feature_consistency(self, X: pd.DataFrame) -> pd.DataFrame:
        """Ensure feature consistency with training data"""
        
        if self.feature_names is None:
            self.logger.warning("No training feature names stored, using current features")
            return X
        
        # Check if we have the same features as during training
        current_features = set(X.columns)
        training_features = set(self.feature_names)
        
        if current_features != training_features:
            # Only log detailed mismatch info in debug mode to reduce noise
            if len(current_features) > len(training_features) * 2:  # Significant mismatch
                self.logger.warning(f"LSTM Feature mismatch detected! Training: {len(training_features)} features, Prediction: {len(current_features)} features")
            
            # Add missing features with default values
            missing_features = training_features - current_features
            if missing_features:
                for feature in missing_features:
                    X[feature] = 0.0
            
            # Remove extra features (keep only training features)
            extra_features = current_features - training_features
            if extra_features:
                X = X.drop(columns=list(extra_features))
            
            # Reorder columns to match training order
            X = X[self.feature_names]
        
        return X

# ===== REINFORCEMENT LEARNING SYSTEM =====
class PortfolioEnvironment(gym.Env):
    """Environment cho portfolio management v·ªõi RL"""
    
    def __init__(self, data_manager: EnhancedDataManager, feature_engineer: AdvancedFeatureEngineer):
        super(PortfolioEnvironment, self).__init__()
        
        self.data_manager = data_manager
        self.feature_engineer = feature_engineer
        self.logger = LOG_MANAGER.get_logger('RLAgent')
        
        # Symbols
        self.symbols = Config.SYMBOLS
        self.n_symbols = len(self.symbols)
        
        # Action space: allocation weights cho m·ªói symbol (-1 to 1), t·ªïng v·ªÅ 0
        self.action_space = spaces.Box(low=-1, high=1, shape=(self.n_symbols,), dtype=np.float32)
        
        # Observation space: market state cho m·ªói symbol
        self.observation_space = spaces.Box(
            low=-np.inf, 
            high=np.inf, 
            shape=(self.n_symbols * 30,),  # 30 features per symbol
            dtype=np.float32
        )
        
        # Portfolio state
        self.reset()
    
    def reset(self):
        """Reset environment"""
        self.current_step = Config.FEATURE_WINDOW
        self.portfolio_value = 100000  # Starting value $100k
        self.cash = 100000
        self.positions = {symbol: 0 for symbol in self.symbols}
        self.trade_history = []
        self.daily_returns = []
        
        return self._get_observation()
    
    def _get_observation(self) -> np.ndarray:
        """L·∫•y observation state"""
        observation = []
        
        for symbol in self.symbols:
            # Simplified market state - trong th·ª±c t·∫ø s·∫Ω fetch real data
            market_features = np.random.randn(30)  # Random features
            observation.extend(market_features)
        
        return np.array(observation, dtype=np.float32)
    
    def step(self, action: np.ndarray):
        """Execute action v√† return (observation, reward, done, info)"""
        
        # Normalize action ƒë·ªÉ t·ªïng b√¨nh ph∆∞∆°ng = 1
        action = action / (np.linalg.norm(action) + 1e-8)
        
        # Execute trades
        self._execute_trades(action)
        
        # Calculate returns
        portfolio_return = self._calculate_portfolio_return(action)
        
        # Calculate reward
        reward = self._calculate_reward(portfolio_return, action)
        
        # Update state
        self.current_step += 1
        
        # Check if done
        done = self.current_step >= 1000  # Max 1000 steps
        
        # Get next observation
        obs = self._get_observation()
        
        info = {
            'portfolio_value': self.portfolio_value,
            'daily_return': portfolio_return,
            'positions': self.positions.copy(),
            'action': action.tolist()
        }
        
        return obs, reward, done, info
    
    def _execute_trades(self, action: np.ndarray):
        """Execute trading action"""
        for i, symbol in enumerate(self.symbols):
            target_weight = action[i]
            current_weight = self.positions[symbol] * self._get_symbol_price(symbol) / self.portfolio_value
            
            weight_change = target_weight - current_weight
            
            if abs(weight_change) > 0.01:  # Minimum trade threshold
                self.positions[symbol] += weight_change * self.portfolio_value / self._get_symbol_price(symbol)
                self.trade_history.append({
                    'symbol': symbol,
                    'action': weight_change,
                    'timestamp': self.current_step
                })
    
    def _calculate_portfolio_return(self, action: np.ndarray) -> float:
        """T√≠nh portfolio return"""
        # Simplified - trong th·ª±c t·∫ø s·∫Ω t√≠nh t·ª´ price movements
        portfolio_return = np.mean(np.random.randn(self.n_symbols)) * 0.01
        self.daily_returns.append(portfolio_return)
        
        # Update portfolio value
        self.portfolio_value *= (1 + portfolio_return)
        
        return portfolio_return
    
    def _calculate_reward(self, portfolio_return: float, action: np.ndarray) -> float:
        """T√≠nh reward function d·ª±a tr√™n Sharpe ratio v√† c√°c y·∫øu t·ªë kh√°c"""
        
        # Base reward: Sharpe ratio
        if len(self.daily_returns) >= 10:
            sharpe_ratio = np.mean(self.daily_returns) / (np.std(self.daily_returns) + 1e-8)
            sharpe_reward = sharpe_ratio * 100
        else:
            sharpe_reward = portfolio_return * 100
        
        # Penalty for extreme positions
        position_penalty = -np.sum(np.abs(action)) * 0.1
        
        # Penalty for frequent trading
        trading_penalty = -len([t for t in self.trade_history if t['timestamp'] == self.current_step]) * 0.05
        
        total_reward = sharpe_reward + position_penalty + trading_penalty
        
        return total_reward
    
    def _get_symbol_price(self, symbol: str) -> float:
        """L·∫•y gi√° symbol hi·ªán t·∫°i"""
        # Simplified - return random price
        base_prices = {'XAUUSD': 2000, 'EURUSD': 1.1, 'NAS100': 15000, 'BTCUSD': 40000}
        base_price = base_prices.get(symbol, 1.0)
        noise = np.random.randn() * base_price * 0.01
        return base_price + noise
    
    def render(self):
        """Render environment state"""
        self.logger.info(f"Portfolio Value: ${self.portfolio_value:,.2f}")
        self.logger.info(f"Positions: {self.positions}")
        self.logger.info(f"Daily Returns (last 5): {self.daily_returns[-5:]}")

class TrainingCallback(BaseCallback):
    """Custom callback cho RL training"""
    
    def __init__(self, check_freq: int = 10000, verbose: int = 1):
        super(TrainingCallback, self).__init__(verbose)
        self.check_freq = check_freq
        self._logger = LOG_MANAGER.get_logger('RLAgent')
    
    def _on_step(self) -> bool:
        """Called for each step"""
        
        if self.n_calls % self.check_freq == 0:
            # Log training progress
            if hasattr(self.model, 'logger'):
                self._logger.info(f"RL Training step {self.n_calls}")
        
        # Early stopping check
        if hasattr(self.training_env, 'get_attr'):
            portfolio_values = self.training_env.get_attr('portfolio_values', [0])
            if len(portfolio_values) > 0:
                current_value = portfolio_values[0][-1] if portfolio_values[0] else 100000
                
                # Stop if portfolio drops below 70% of starting value
                if current_value < 70000:
                    self._logger.warning("Portfolio value qu√° th·∫•p, d·ª´ng training")
                    return False
        
        return True

class TrendSpecialistAgent:
    """Specialist Agent cho trend analysis v√† market regime detection"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('TrendSpecialistAgent')
        self.trend_signals = {}
        self.market_regime = None
        
    async def analyze_trend(self, symbol: str, data: dict) -> dict:
        """Ph√¢n t√≠ch trend cho symbol c·ª• th·ªÉ"""
        try:
            if symbol not in data or data[symbol].empty:
                return {'trend': 'UNKNOWN', 'confidence': 0.0, 'strength': 0.0}
            
            df = data[symbol].copy()
            
            # Technical indicators cho trend analysis
            if len(df) >= 20:
                df['sma_20'] = df['close'].rolling(window=20).mean()
                df['sma_50'] = df['close'].rolling(window=50).mean()
                df['ema_12'] = df['close'].ewm(span=12).mean()
                df['ema_26'] = df['close'].ewm(span=26).mean()
                
                # Trend determination
                current_price = df['close'].iloc[-1]
                sma_20 = df['sma_20'].iloc[-1]
                sma_50 = df['sma_50'].iloc[-1]
                
                if current_price > sma_20 > sma_50:
                    trend = 'UPTREND'
                    confidence = 0.8
                elif current_price < sma_20 < sma_50:
                    trend = 'DOWNTREND'
                    confidence = 0.8
                elif sma_20 > sma_50:
                    trend = 'UPTREND'
                    confidence = 0.6
                elif sma_20 < sma_50:
                    trend = 'DOWNTREND'
                    confidence = 0.6
                else:
                    trend = 'SIDEWAYS'
                    confidence = 0.4
                
                # Strength calculation
                price_variance = df['close'].rolling(window=20).std().iloc[-1]
                strength = min(1.0, price_variance / current_price * 100)
                
            else:
                trend = 'INSUFFICIENT_DATA'
                confidence = 0.0
                strength = 0.0
            
            result = {
                'trend': trend,
                'confidence': confidence,
                'strength': strength,
                'timestamp': datetime.now().isoformat()
            }
            
            self.trend_signals[symbol] = result
            return result
            
        except Exception as e:
            self.logger.error(f"L·ªói trong trend analysis cho {symbol}: {e}")
            return {'trend': 'ERROR', 'confidence': 0.0, 'strength': 0.0}
    
    def get_trend_recommendation(self, symbol: str) -> dict:
        """L·∫•y recommendation t·ª´ trend analysis"""
        if symbol in self.trend_signals:
            signal = self.trend_signals[symbol]
            return {
                'action': 'HOLD' if signal['trend'] == 'SIDEWAYS' else ('BUY' if signal['trend'] == 'UPTREND' else 'SELL'),
                'confidence': signal['confidence'],
                'reasoning': f"Trend analysis shows {signal['trend']} with {signal['confidence']:.2f} confidence"
            }
        return {'action': 'HOLD', 'confidence': 0.0, 'reasoning': 'No trend data available'}

class RiskSpecialistAgent:
    """Specialist Agent cho risk assessment v√† position sizing"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('RiskSpecialistAgent')
        self.risk_assessments = {}
        
    async def assess_risk(self, symbol: str, data: dict, portfolio_value: float) -> dict:
        """ƒê√°nh gi√° risk cho symbol"""
        try:
            if symbol not in data or data[symbol].empty:
                return {'risk_level': 'HIGH', 'position_size': 0.0, 'confidence': 0.0}
            
            df = data[symbol].copy()
            
            # Risk metrics
            if len(df) >= 20:
                # Volatility (ATR)
                df['high_low'] = df['high'] - df['low']
                df['high_close'] = abs(df['high'] - df['close'].shift(1))
                df['low_close'] = abs(df['low'] - df['close'].shift(1))
                df['tr'] = df[['high_low', 'high_close', 'low_close']].max(axis=1)
                atr = df['tr'].rolling(window=14).mean().iloc[-1]
                current_price = df['close'].iloc[-1]
                
                # Volatility percentage
                volatility_pct = (atr / current_price) * 100
                
                # Risk level determination
                if volatility_pct < 1.0:
                    risk_level = 'LOW'
                    position_size = 0.02  # 2%
                elif volatility_pct < 2.0:
                    risk_level = 'MEDIUM'
                    position_size = 0.015  # 1.5%
                else:
                    risk_level = 'HIGH'
                    position_size = 0.01   # 1%
                
                # Recent drawdown
                recent_high = df['close'].rolling(window=20).max().iloc[-1]
                drawdown = ((recent_high - current_price) / recent_high) * 100
                
                confidence = 0.8 if len(df) >= 50 else 0.6
                
            else:
                risk_level = 'HIGH'
                position_size = 0.005  # 0.5% default
                volatility_pct = 5.0
                drawdown = 0.0
                confidence = 0.0
            
            result = {
                'risk_level': risk_level,
                'position_size': position_size,
                'volatility_pct': volatility_pct,
                'drawdown': drawdown,
                'confidence': confidence,
                'recommended_stop_loss': position_size * 0.5,  # 50% of position as stop loss
                'timestamp': datetime.now().isoformat()
            }
            
            self.risk_assessments[symbol] = result
            return result
            
        except Exception as e:
            self.logger.error(f"L·ªói trong risk assessment cho {symbol}: {e}")
            return {'risk_level': 'HIGH', 'position_size': 0.0, 'confidence': 0.0}
    
    def get_risk_recommendation(self, symbol: str) -> dict:
        """L·∫•y risk recommendation"""
        if symbol in self.risk_assessments:
            assessment = self.risk_assessments[symbol]
            return {
                'max_position_size': assessment['position_size'],
                'risk_level': assessment['risk_level'],
                'stop_loss_size': assessment['recommended_stop_loss'],
                'confidence': assessment['confidence']
            }
        return {
            'max_position_size': 0.01,  # Default 1%
            'risk_level': 'MEDIUM',
            'stop_loss_size': 0.005,
            'confidence': 0.0
        }

class NewsSpecialistAgent:
    """Specialist Agent cho news v√† sentiment analysis"""
    
    def __init__(self, news_manager):
        self.logger = LOG_MANAGER.get_logger('NewsSpecialistAgent')
        self.news_manager = news_manager
        self.sentiment_cache = {}
        
    async def analyze_sentiment(self, symbol: str, hours_back: int = 24) -> dict:
        """Ph√¢n t√≠ch sentiment t·ª´ news"""
        try:
            if not self.news_manager:
                return {'sentiment': 'NEUTRAL', 'confidence': 0.0, 'impact': 'LOW'}
            
            # Get latest news
            news_data = await self.news_manager.fetch_news_sentiment(symbol, hours_back)
            
            if not news_data or not news_data.get('latest_news_items'):
                return {'sentiment': 'NEUTRAL', 'confidence': 0.0, 'impact': 'LOW'}
            
            # Analyze sentiment using Gemini
            sentiment_scores = []
            impact_keywords = ['fomc', 'nfp', 'gdp', 'inflation', 'interest rate', 'fed', 'central bank']
            
            for article in news_data['latest_news_items'][:10]:  # Limit to 10 articles
                text = article.get('text', '')
                title = text  # Use text as both title and description
                description = text
                
                # Check for high impact keywords
                high_impact = any(keyword in (title + description).lower() for keyword in impact_keywords)
                
                # Simple sentiment analysis (positive/negative keywords)
                text = f"{title} {description}".lower()
                positive_words = ['positive', 'growth', 'strong', 'increase', 'rise', 'bullish', 'surge', 'gains']
                negative_words = ['negative', 'decline', 'weak', 'decrease', 'fall', 'bearish', 'drop', 'loss']
                
                positive_count = sum(1 for word in positive_words if word in text)
                negative_count = sum(1 for word in negative_words if word in text)
                
                if positive_count > negative_count:
                    sentiment_scores.append(1.0 if high_impact else 0.5)
                elif negative_count > positive_count:
                    sentiment_scores.append(-1.0 if high_impact else -0.5)
                else:
                    sentiment_scores.append(0.0)
            
            if not sentiment_scores:
                return {'sentiment': 'NEUTRAL', 'confidence': 0.0, 'impact': 'LOW'}
            
            # Calculate overall sentiment
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
            
            if avg_sentiment > 0.3:
                sentiment = 'POSITIVE'
                confidence = min(1.0, abs(avg_sentiment))
            elif avg_sentiment < -0.3:
                sentiment = 'NEGATIVE'
                confidence = min(1.0, abs(avg_sentiment))
            else:
                sentiment = 'NEUTRAL'
                confidence = 0.5
            
            impact = 'HIGH' if any(abs(score) >= 0.8 for score in sentiment_scores) else 'MEDIUM' if confidence > 0.6 else 'LOW'
            
            result = {
                'sentiment': sentiment,
                'confidence': confidence,
                'impact': impact,
                'news_count': len(news_data['latest_news_items']),
                'timestamp': datetime.now().isoformat()
            }
            
            self.sentiment_cache[symbol] = result
            return result
            
        except Exception as e:
            self.logger.error(f"L·ªói trong sentiment analysis cho {symbol}: {e}")
            return {'sentiment': 'NEUTRAL', 'confidence': 0.0, 'impact': 'LOW'}
    
    def get_sentiment_recommendation(self, symbol: str) -> dict:
        """L·∫•y sentiment recommendation"""
        if symbol in self.sentiment_cache:
            sentiment_data = self.sentiment_cache[symbol]
            return {
                'sentiment': sentiment_data['sentiment'],
                'confidence': sentiment_data['confidence'],
                'impact': sentiment_data['impact'],
                'news_count': sentiment_data['news_count']
            }
        return {
            'sentiment': 'NEUTRAL',
            'confidence': 0.0,
            'impact': 'LOW',
            'news_count': 0
        }

class MasterAgent:
    """Master Agent ƒëi·ªÅu ph·ªëi t·∫•t c·∫£ specialist agents v√† AI models"""
    
    def __init__(self, trend_agent, news_agent, risk_agent, ensemble_model=None, lstm_model=None, rl_agent=None, feature_engineer=None):
        self.logger = LOG_MANAGER.get_logger('MasterAgent')
        self.trend_agent = trend_agent
        self.news_agent = news_agent
        self.risk_agent = risk_agent
        self.ensemble_model = ensemble_model
        self.lstm_model = lstm_model
        self.rl_agent = rl_agent
        self.feature_engineer = feature_engineer
        self.decisions = {}
        self.ensemble_weight = 0.4
        self.lstm_weight = 0.3
        self.expert_weight = 0.3
        self.cycle_count = 0
        
    async def make_decision(self, symbol: str, data: dict, portfolio_value: float) -> dict:
        """ƒê∆∞a ra quy·∫øt ƒë·ªãnh trading cu·ªëi c√πng s·ª≠ d·ª•ng Ensemble AI v√† Expert Systems"""
        try:
            self.logger.info(f"ü§ñ Master Agent ƒëang ph√¢n t√≠ch {symbol} v·ªõi AI models...")
            
            # 1. Collect insights t·ª´ expert specialist agents
            trend_insight = await self.trend_agent.analyze_trend(symbol, data)
            sentiment_insight = await self.news_agent.analyze_sentiment(symbol)
            risk_assessment = await self.risk_agent.assess_risk(symbol, data, portfolio_value)
            
            # 2. Get AI Model predictions
            ensemble_prediction = None
            lstm_prediction = None
            rl_action = None
            
            # Ensemble Model prediction
            if self.ensemble_model and hasattr(self.ensemble_model, 'predict'):
                try:
                    # Check if ensemble model is properly trained
                    if not self.ensemble_model.models or not self.ensemble_model.meta_model:
                        self.logger.warning("Ensemble model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán")
                        ensemble_prediction = None
                    else:
                        # Convert data to DataFrame for ensemble prediction
                        import pandas as pd
                        
                        # Convert enriched DataFrame to prediction-ready format
                        if isinstance(data, pd.DataFrame):
                            # Use only the latest row (most recent data)
                            latest_data = data.iloc[-1:].copy()
                            
                            # Remove non-feature columns for prediction
                            prediction_features = latest_data.drop(
                                columns=[col for col in latest_data.columns 
                                        if col in ['datetime', 'timestamp'] or col.startswith('_')]
                            )
                            
                            ensemble_pred, ensemble_conf = self.ensemble_model.predict(prediction_features)
                        else:
                            # Handle dict/other data types
                            features_df = pd.DataFrame([data])
                            ensemble_pred, ensemble_conf = self.ensemble_model.predict(features_df)
                        
                        ensemble_prediction = {
                            'action': 'BUY' if ensemble_pred[0] > 0.5 else 'SELL' if ensemble_pred[0] < 0.3 else 'HOLD',
                            'confidence': ensemble_conf[0],
                            'probability': ensemble_pred[0]
                        }
                        self.logger.info(f"üéØ Ensemble prediction: {ensemble_prediction}")
                except Exception as e:
                    self.logger.warning(f"Ensemble model error: {e}")
                    ensemble_prediction = None
            
            # LSTM Model prediction
            if self.lstm_model and hasattr(self.lstm_model, 'predict'):
                try:
                    # Check if LSTM model is trained
                    if not self.lstm_model.is_trained:
                        self.logger.warning("LSTM model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán")
                        lstm_prediction = None
                    else:
                        # Prepare data for LSTM prediction
                        if isinstance(data, pd.DataFrame):
                            # Use only the latest rows for sequence prediction
                            seq_len = getattr(self.lstm_model, 'sequence_length', 50)
                            lstm_data = data.tail(seq_len + 1).copy()
                            
                            # Remove non-feature columns but keep all numeric features
                            lstm_features = lstm_data.select_dtypes(include=[np.number]).fillna(0)
                        else:
                            # Handle dict/other data types - convert to DataFrame with numeric features only
                            lstm_features = pd.DataFrame([data]).select_dtypes(include=[np.number]).fillna(0)
                        
                        lstm_pred, lstm_conf = self.lstm_model.predict(lstm_features)
                        
                        # Handle array inputs properly
                        if isinstance(lstm_pred, np.ndarray):
                            lstm_pred_val = lstm_pred[0] if len(lstm_pred) > 0 else 0.5
                        elif isinstance(lstm_pred, (int, float)):
                            lstm_pred_val = float(lstm_pred)
                        else:
                            self.logger.warning(f"Unexpected LSTM pred type: {type(lstm_pred)}")
                            lstm_pred_val = 0.5
                            
                        if isinstance(lstm_conf, np.ndarray):
                            lstm_conf_val = lstm_conf[0] if len(lstm_conf) > 0 else 0.5
                        elif isinstance(lstm_conf, (int, float)):
                            lstm_conf_val = float(lstm_conf)
                        else:
                            self.logger.warning(f"Unexpected LSTM conf type: {type(lstm_conf)}")
                            lstm_conf_val = 0.5
                        
                        lstm_prediction = {
                            'action': 'BUY' if lstm_pred_val > 0.6 else 'SELL' if lstm_pred_val < 0.4 else 'HOLD',
                            'confidence': lstm_conf_val,
                            'probability': lstm_pred_val
                        }
                        self.logger.info(f"üß† LSTM prediction: {lstm_prediction}")
                except Exception as e:
                    self.logger.warning(f"LSTM model error: {e}")
                    lstm_prediction = None
            
            # RL Agent action
            if self.rl_agent and self.rl_agent.model:
                try:
                    # Get latest features for RL prediction
                    if isinstance(data, pd.DataFrame):
                        # Use the latest row (most recent data)
                        latest_data = data.iloc[-1:].copy()
                        
                        # Engineer features for RL prediction
                        if self.feature_engineer:
                            features_df = self.feature_engineer.engineer_all_features(latest_data, symbol)
                            
                            # Get numeric features only (exclude datetime, timestamp, etc.)
                            prediction_features = features_df.select_dtypes(include=[np.number])
                            
                            # Convert to numpy array for RL model
                            observation = prediction_features.values.astype(np.float32)
                            
                            # Ensure observation matches expected shape
                            if len(observation) > 0:
                                observation = observation.flatten()
                                
                                # Pad or truncate to match RL model's expected input size
                                if hasattr(self.rl_agent.environment, 'observation_space'):
                                    expected_size = self.rl_agent.environment.observation_space.shape[0]
                                    if len(observation) < expected_size:
                                        observation = np.pad(observation, (0, expected_size - len(observation)), 'constant')
                                    elif len(observation) > expected_size:
                                        observation = observation[:expected_size]
                                
                                # Get RL prediction
                                action, _ = self.rl_agent.model.predict(observation, deterministic=True)
                                
                                rl_action = {
                                    'action': 'BUY' if action == 0 else 'SELL' if action == 1 else 'HOLD',
                                    'confidence': 0.7,  # Default RL confidence
                                    'action_id': action
                                }
                                self.logger.info(f"ü§ñ RL Agent action: {rl_action}")
                            else:
                                self.logger.warning("No features available for RL prediction")
                                rl_action = None
                        else:
                            self.logger.warning("Feature engineer not available for RL prediction")
                            rl_action = None
                    else:
                        self.logger.warning("Data format not supported for RL prediction")
                        rl_action = None
                        
                except Exception as e:
                    self.logger.warning(f"RL Agent error: {e}")
                    rl_action = None
            
            # 3. Weighted Ensemble Decision Making
            expert_votes = {'BUY': 0, 'SELL': 0, 'HOLD': 0}
            
            # Expert system votes
            trend_recommendation = self.trend_agent.get_trend_recommendation(symbol)
            expert_votes[trend_recommendation['action']] += trend_recommendation['confidence'] * self.expert_weight
            
            sentiment_recommendation = self.news_agent.get_sentiment_recommendation(symbol)
            if sentiment_recommendation['sentiment'] == 'POSITIVE':
                expert_votes['BUY'] += sentiment_recommendation['confidence'] * self.expert_weight
            elif sentiment_recommendation['sentiment'] == 'NEGATIVE':
                expert_votes['SELL'] += sentiment_recommendation['confidence'] * self.expert_weight
            else:
                expert_votes['HOLD'] += sentiment_recommendation['confidence'] * self.expert_weight
            
            # Combine AI predictions with expert systems
            if ensemble_prediction:
                expert_votes[ensemble_prediction['action']] += ensemble_prediction['confidence'] * self.ensemble_weight
            if lstm_prediction:
                expert_votes[lstm_prediction['action']] += lstm_prediction['confidence'] * self.lstm_weight
            if rl_action:
                expert_votes[rl_action['action']] += rl_action['confidence'] * 0.3  # RL weight
            
            # 4. Final weighted decision
            best_action = max(expert_votes, key=expert_votes.get)
            confidence = expert_votes[best_action] / max(sum(expert_votes.values()), 0.1)
            
            # Risk-based override
            max_position_size = risk_assessment['position_size']
            if risk_assessment['risk_level'] == 'HIGH' and best_action != 'HOLD':
                best_action = 'HOLD'
                confidence *= 0.5
                self.logger.info(f"‚ö†Ô∏è Risk override: HIGH risk forces HOLD")
            
            # Calculate ensemble confidence boost
            if ensemble_prediction and lstm_prediction:
                ai_consensus = abs(ensemble_prediction['probability'] - 0.5) + abs(lstm_prediction['probability'] - 0.5)
                confidence = min(confidence + ai_consensus * 0.2, 1.0)
            
            decision = {
                'action': best_action,
                'confidence': min(confidence, 1.0),
                'position_size': min(max_position_size, 0.02),
                'ai_predictions': {
                    'ensemble': ensemble_prediction,
                    'lstm': lstm_prediction,
                    'rl': rl_action
                },
                'reasoning': {
                    'trend': trend_recommendation,
                    'sentiment': sentiment_recommendation,
                    'risk': {
                        'level': risk_assessment['risk_level'],
                        'max_size': risk_assessment['position_size']
                    },
                    'weights': {
                        'ensemble': self.ensemble_weight,
                        'lstm': self.lstm_weight,
                        'expert': self.expert_weight
                    }
                },
                'timestamp': datetime.now().isoformat()
            }
            
            self.decisions[symbol] = decision
            self.logger.info(f"‚úÖ Master Agent quy·∫øt ƒë·ªãnh: {best_action} {symbol} v·ªõi confidence {confidence:.2f} (AI-Enhanced)")
            
            return decision
            
        except Exception as e:
            self.logger.error(f"L·ªói trong decision making cho {symbol}: {e}")
            return {
                'action': 'HOLD',
                'confidence': 0.0,
                'position_size': 0.0,
                'reasoning': {'error': str(e)},
                'timestamp': datetime.now().isoformat()
            }
    
    def get_last_decision(self, symbol: str) -> dict:
        """L·∫•y decision g·∫ßn nh·∫•t cho symbol"""
        return self.decisions.get(symbol, {
            'action': 'HOLD',
            'confidence': 0.0,
            'timestamp': datetime.now().isoformat()
        })
    
    async def analyze_and_decide(self, enriched_data: dict, portfolio_status: dict) -> dict:
        """Analyze enriched data from all symbols and make comprehensive trading decisions"""
        try:
            self.logger.info("ü§ñ Master Agent analyzing enriched data for trading decisions...")
            symbols_with_data = list(enriched_data.keys())
            self.logger.info(f"üìä Symbols c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch: {', '.join(symbols_with_data)}")
            
            # Increment cycle count for training triggers
            self.cycle_count += 1
            
            decisions = {}
            buy_signals = []
            sell_signals = []
            
            # Analyze each symbol in enriched data
            for symbol, features_data in enriched_data.items():
                if features_data is None or features_data.empty:
                    continue
                    
                # Get latest row for decision making
                latest_data = features_data.iloc[-1].to_dict()
                
                # Trigger AI training if we have enough data (every 500 cycles ho·∫∑c khi performance th·∫•p)
                if len(features_data) >= 50 and self.cycle_count % 500 == 0:
                    self.logger.info(f"üîÑ Triggering AI training cho {symbol}...")
                    training_result = await self.trigger_ai_training(symbol, features_data)
                    self.logger.info(f"üéì Training result: {training_result.get('status', 'unknown')}")
                
                # Make individual decision for this symbol
                individual_decision = await self.make_decision(symbol, latest_data, portfolio_status.get('total_value', 100000))
                decisions[symbol] = individual_decision
                
                # Collect signals
                if individual_decision['action'] == 'BUY' and individual_decision['confidence'] > 0.6:
                    buy_signals.append({
                        'symbol': symbol,
                        'confidence': individual_decision['confidence'],
                        'position_size': individual_decision.get('position_size', 0.02)
                    })
                elif individual_decision['action'] == 'SELL' and individual_decision['confidence'] > 0.6:
                    sell_signals.append({
                        'symbol': symbol,
                        'confidence': individual_decision['confidence'],
                        'position_size': individual_decision.get('position_size', 0.02)
                    })
            
            # Calculate overall signal strength
            total_confidence = sum(s['confidence'] for s in buy_signals + sell_signals)
            signal_count = len(buy_signals) + len(sell_signals)
            signal_strength = total_confidence / max(signal_count, 1) if signal_count > 0 else 0
            
            # Determine market regime
            market_regime = 'NEUTRAL'
            if len(buy_signals) > len(sell_signals) and signal_strength > 0.7:
                market_regime = 'BULLISH'
            elif len(sell_signals) > len(buy_signals) and signal_strength > 0.7:
                market_regime = 'BEARISH'
            
            # Comprehensive decision
            comprehensive_decision = {
                'signal_strength': signal_strength,
                'confidence': signal_strength,
                'market_regime': market_regime,
                'buy_signals': buy_signals,
                'sell_signals': sell_signals,
                'individual_decisions': decisions,
                'portfolio_status': portfolio_status,
                'total_signals': len(buy_signals) + len(sell_signals),
                'recommended_action': 'BUY' if market_regime == 'BULLISH' else 'SELL' if market_regime == 'BEARISH' else 'HOLD',
                'timestamp': datetime.now().isoformat()
            }
            
            self.logger.info(f"‚úÖ Master Agent analysis complete: {market_regime} market, {signal_strength:.2f} signal strength, {len(buy_signals)} buy, {len(sell_signals)} sell")
            
            return comprehensive_decision
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói trong analyze_and_decide: {e}")
            return {
                'signal_strength': 0.0,
                'confidence': 0.0,
                'market_regime': 'NEUTRAL',
                'buy_signals': [],
                'sell_signals': [],
                'individual_decisions': {},
                'portfolio_status': portfolio_status,
                'total_signals': 0,
                'recommended_action': 'HOLD',
                'timestamp': datetime.now().isoformat(),
                'error': str(e)
            }
    
    async def trigger_ai_training(self, symbol: str, recent_data: pd.DataFrame) -> dict:
        """Trigger AI model training khi c√≥ ƒë·ªß d·ªØ li·ªáu"""
        try:
            if recent_data.empty or len(recent_data) < 50:
                return {'status': 'insufficient_data', 'data_points': len(recent_data)}
            
            self.logger.info(f"üéì Training AI models cho {symbol} v·ªõi {len(recent_data)} data points...")
            
            # Prepare features v√† labels cho training
            features = recent_data.drop(['close'], axis=1, errors='ignore')
            labels = (recent_data['close'].shift(-1) > recent_data['close']).astype(int)[:-1]
            features = features.iloc[:-1]  # Remove last row ƒë·ªÉ match labels
            
            training_results = {}
            
            # Train Ensemble Model
            if self.ensemble_model and hasattr(self.ensemble_model, 'train_ensemble'):
                try:
                    self.logger.info("üéØ Starting Ensemble model training...")
                    ensemble_scores = self.ensemble_model.train_ensemble(features, labels)
                    training_results['ensemble'] = ensemble_scores
                    if 'error' in ensemble_scores:
                        self.logger.error(f"‚ùå Ensemble training failed: {ensemble_scores['error']}")
                    else:
                        self.logger.info(f"‚úÖ Ensemble training completed - Accuracy: {ensemble_scores.get('accuracy', 0):.3f}")
                except Exception as e:
                    self.logger.error(f"‚ùå Ensemble training failed: {e}")
                    training_results['ensemble'] = {'error': str(e)}
            else:
                self.logger.warning("‚ö†Ô∏è Ensemble model not available or missing train_ensemble method")
            
            # Train LSTM Model
            if self.lstm_model and hasattr(self.lstm_model, 'train'):
                try:
                    self.logger.info("üß† Starting LSTM model training...")
                    lstm_scores = self.lstm_model.train(features, labels)
                    training_results['lstm'] = lstm_scores
                    if 'error' in lstm_scores:
                        self.logger.error(f"‚ùå LSTM training failed: {lstm_scores['error']}")
                    else:
                        self.logger.info(f"‚úÖ LSTM training completed - Validation Accuracy: {lstm_scores.get('val_accuracy', 0):.3f}")
                except Exception as e:
                    self.logger.error(f"‚ùå LSTM training failed: {e}")
                    training_results['lstm'] = {'error': str(e)}
            else:
                self.logger.warning("‚ö†Ô∏è LSTM model not available or missing train method")
            
            # Train RL Agent
            if self.rl_agent and self.rl_agent.model:
                try:
                    self.logger.info("ü§ñ Starting RL Agent training...")
                    rl_result = self.rl_agent.train(total_timesteps=50000)
                    training_results['rl'] = rl_result
                    if 'error' in rl_result:
                        self.logger.error(f"‚ùå RL training failed: {rl_result['error']}")
                    else:
                        self.logger.info("‚úÖ RL Agent training completed")
                except Exception as e:
                    self.logger.error(f"‚ùå RL training failed: {e}")
                    training_results['rl'] = {'error': str(e)}
            else:
                self.logger.warning("‚ö†Ô∏è RL Agent not available or model not created")
            
            # C·∫≠p nh·∫≠t model weights n·∫øu training th√†nh c√¥ng
            trained_models = [k for k, v in training_results.items() if 'error' not in str(v)]
            failed_models = [k for k, v in training_results.items() if 'error' in str(v)]
            
            self.logger.info(f"üìä Training Summary:")
            self.logger.info(f"   ‚úÖ Successfully trained: {trained_models}")
            self.logger.info(f"   ‚ùå Failed to train: {failed_models}")
            
            if len(trained_models) >= 2:
                # Boost confidence weight c·ªßa c√°c models trained
                self.ensemble_weight = 0.5
                self.lstm_weight = 0.4
                self.expert_weight = 0.1
                self.logger.info(f"üéØ Model weights updated after training: {trained_models}")
            elif len(trained_models) >= 1:
                self.logger.warning(f"‚ö†Ô∏è Only {len(trained_models)} model(s) trained successfully")
            else:
                self.logger.error("‚ùå No models trained successfully!")
            
            return {
                'status': 'success' if len(trained_models) > 0 else 'partial_failure',
                'trained_models': trained_models,
                'failed_models': failed_models,
                'results': training_results,
                'updated_weights': {
                    'ensemble': self.ensemble_weight,
                    'lstm': self.lstm_weight,
                    'expert': self.expert_weight
                }
            }
            
        except Exception as e:
            self.logger.error(f"AI training failed: {e}")
            return {'status': 'error', 'message': str(e)}

class RLAgent:
    """RL Agent s·ª≠ d·ª•ng PPO t·ª´ stable-baselines3"""
    
    def __init__(self, environment: PortfolioEnvironment):
        self.environment = environment
        self.logger = LOG_MANAGER.get_logger('RLAgent')
        self.model = None
        self.training_history = []
    
    def create_model(self, policy: str = "MlpPolicy"):
        """T·∫°o PPO model"""
        
        # Callback cho training monitoring
        callback = TrainingCallback(check_freq=5000)
        
        # Create PPO model
        self.model = PPO(
            policy=policy,
            env=self.environment,
            verbose=1,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=64,
            n_epochs=10,
            clip_range=0.2,
            ent_coef=0.01,
            vf_coef=0.5,
            max_grad_norm=0.5,
            tensorboard_log="./rl_tensorboard/"
        )
        
        self.logger.info("ƒê√£ t·∫°o PPO model")
        return self.model
    
    def train(self, total_timesteps: int = 100000) -> Dict[str, Any]:
        """Hu·∫•n luy·ªán RL agent"""
        
        try:
            if not self.model:
                self.logger.info("Creating RL model...")
                self.create_model()
            
            if not self.model:
                self.logger.error("Failed to create RL model")
                return {'error': 'Model creation failed'}
            
            self.logger.info(f"B·∫Øt ƒë·∫ßu training RL agent trong {total_timesteps} steps")
            
            # Train model with error handling
            try:
                self.logger.info("Starting RL model training...")
                with self.model.env.envs[0] as env:
                    self.model.learn(
                        total_timesteps=total_timesteps,
                        callback=TrainingCallback(),
                        progress_bar=True
                    )
                self.logger.info("‚úÖ RL model training completed")
            except Exception as e:
                self.logger.error(f"RL training failed: {e}")
                return {'error': f'Training failed: {str(e)}'}
            
            # Save model with error handling
            try:
                self.logger.info("Saving RL model...")
                self.model.save("ppo_trading_agent")
                self.logger.info("‚úÖ RL model saved successfully")
            except Exception as e:
                self.logger.error(f"Failed to save RL model: {e}")
                return {
                    'total_timesteps': total_timesteps,
                    'training_completed': True,
                    'save_error': str(e)
                }
            
            self.logger.info("ƒê√£ ho√†n th√†nh RL training")
            
            return {
                'total_timesteps': total_timesteps,
                'training_completed': True
            }
            
        except Exception as e:
            self.logger.error(f"RL training failed: {e}")
            return {'error': f'Training failed: {str(e)}'}
    
    def predict(self, observation) -> Tuple[np.ndarray, Dict]:
        """D·ª± ƒëo√°n action v·ªõi RL model"""
        
        if not self.model:
            self.logger.warning("RL model ch∆∞a ƒë∆∞·ª£c train")
            return np.zeros(self.environment.n_symbols), {}
        
        action, _states = self.model.predict(observation, deterministic=True)
        return action, {'action_distribution': action.tolist()}
    
    def evaluate_performance(self, n_episodes: int = 10) -> Dict[str, float]:
        """ƒê√°nh gi√° performance c·ªßa trained agent"""
        
        if not self.model:
            return {'error': 'Model ch∆∞a ƒë∆∞·ª£c train'}
        
        episode_returns = []
        episode_sharpe_ratios = []
        
        for episode in range(n_episodes):
            obs = self.environment.reset()
            episode_return = 0
            returns = []
            
            done = False
            while not done:
                action, _ = self.predict(obs)
                obs, reward, done, info = self.environment.step(action)
                episode_return += reward
                returns.append(info['daily_return'])
            
            episode_returns.append(episode_return)
            
            # Calculate Sharpe ratio
            if returns:
                sharpe = np.mean(returns) / (np.std(returns) + 1e-8)
                episode_sharpe_ratios.append(sharpe)
        
        performance_metrics = {
            'mean_return': np.mean(episode_returns),
            'return_std': np.std(episode_returns),
            'mean_sharpe': np.mean(episode_sharpe_ratios),
            'episodes_evaluated': n_episodes
        }
        
        self.logger.info(f"RL Performance - Mean Return: {performance_metrics['mean_return']:.2f}, "
                        f"Sharpe: {performance_metrics['mean_sharpe']:.3f}")
        
        return performance_metrics

# ===== AUTO RETRAIN MANAGER V√Ä CONCEPT DRIFT DETECTION =====
class ConceptDriftDetector:
    """Ph√°t hi·ªán concept drift trong d·ªØ li·ªáu th·ªã tr∆∞·ªùng"""
    
    def __init__(self, window_size: int = 100, threshold: float = 0.1):
        self.window_size = window_size
        self.threshold = threshold
        self.logger = LOG_MANAGER.get_logger('AutoRetrainManager')
        self.reference_distribution = None
        self.drift_detected = False
    
    def update_reference(self, data_sample: np.ndarray):
        """C·∫≠p nh·∫≠t distribution tham chi·∫øu"""
        if self.reference_distribution is None:
            self.reference_distribution = np.mean(data_sample, axis=0)
        else:
            # Exponential moving average ƒë·ªÉ c·∫≠p nh·∫≠t reference
            alpha = 0.1
            new_mean = np.mean(data_sample, axis=0)
            self.reference_distribution = alpha * new_mean + (1 - alpha) * self.reference_distribution
    
    def detect_drift(self, new_data: np.ndarray) -> Dict[str, bool]:
        """Ph√°t hi·ªán drift trong d·ªØ li·ªáu m·ªõi"""
        
        results = {
            'distribution_drift': False,
            'statistical_drift': False,
            'overall_drift': False
        }
        
        try:
            if self.reference_distribution is None:
                self.update_reference(new_data)
                return results
            
            # 1. Distribution drift detection
            dist_drift = False
            if len(new_data) >= self.window_size:
                current_mean = np.mean(new_data[-self.window_size:], axis=0)
                
                # Calculate distance between distributions
                distribution_distance = np.linalg.norm(current_mean - self.reference_distribution)
                dist_drift = distribution_distance > self.threshold
            
            results['distribution_drift'] = dist_drift
            
            # 2. Statistical drift detection
            statistical_drift = False
            if len(new_data) >= self.window_size * 2:
                recent_data = new_data[-self.window_size:]
                historical_data = new_data[-self.window_size*2:-self.window_size]
                
                # T-test ƒë·ªÉ so s√°nh means
                from scipy import stats
                try:
                    recent_mean = np.mean(recent_data)
                    historical_mean = np.mean(historical_data)
                    
                    _, p_value = stats.ttest_ind(recent_data.flatten(), historical_data.flatten())
                    statistical_drift = p_value < 0.05 and abs(recent_mean - historical_mean) > self.threshold
                except:
                    statistical_drift = False
            
            results['statistical_drift'] = statistical_drift
            
            # 3. Overall drift assessment
            results['overall_drift'] = dist_drift or statistical_drift
            
            if results['overall_drift']:
                self.logger.warning("Concept drift detected!")
                self.drift_detected = True
            
        except Exception as e:
            self.logger.error(f"L·ªói trong drift detection: {e}")
        
        return results

class OnlineLearningManager:
    """Qu·∫£n l√Ω online learning v·ªõi river framework"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('AutoRetrainManager')
        self.online_models = {}
        
        # Initialize adaptive models cho t·ª´ng symbol
        self.online_models = {}
        for symbol in Config.SYMBOLS:
            self.online_models[symbol] = {
                'linear_model': linear_model.LogisticRegression(),
                'preprocessor': preprocessing.StandardScaler(),
                'anomaly_detector': anomaly.OneClassSVM(),
                'performance_history': [],
                'initialized': False
            }
    
    def _numpy_to_dict(self, features: np.ndarray) -> Dict[str, float]:
        """Convert numpy array to dict format for River framework"""
        if len(features.shape) == 1:
            # 1D array -> dict with numeric keys
            return {f"feature_{i}": float(features[i]) for i in range(len(features))}
        elif len(features.shape) == 2 and features.shape[0] == 1:
            # 2D array with 1 row -> flatten to 1D
            flattened = features.flatten()
            return {f"feature_{i}": float(flattened[i]) for i in range(len(flattened))}
        else:
            # Complex array -> flatten and truncate
            flattened = features.flatten()[:50]  # Limit to 50 features
            return {f"feature_{i}": float(flattened[i]) for i in range(len(flattened))}
    
    def update_model(self, symbol: str, features: np.ndarray, target: float):
        """C·∫≠p nh·∫≠t online model v·ªõi data m·ªõi"""
        
        try:
            if symbol not in self.online_models:
                return
            
            model_info = self.online_models[symbol]
            
            # Convert numpy array to dict for River framework
            features_dict = self._numpy_to_dict(features)
            
            # Preprocess features
            if model_info['preprocessor'] is None:
                self.logger.warning(f"Preprocessor is None for {symbol}, skipping model update")
                return
            
            # Handle case where learn_one returns None (common with River framework)
            preprocessor_result = model_info['preprocessor'].learn_one(features_dict)
            if preprocessor_result is None:
                # For StandardScaler, we can still transform without learning first
                try:
                    scaled_features = model_info['preprocessor'].transform_one(features_dict)
                    model_info['initialized'] = True  # Mark as initialized on successful transform
                except Exception as e:
                    self.logger.warning(f"Could not transform features for {symbol}: {e}. Model not yet initialized with enough data.")
                    return
            else:
                scaled_features = preprocessor_result.transform_one(features_dict)
            
            # Update anomaly detector
            model_info['anomaly_detector'].learn_one(scaled_features)
            
            # Update linear model
            model_info['linear_model'].learn_one(scaled_features, target)
            
            # Track performance
            prediction = model_info['linear_model'].predict_one(scaled_features)
            error = abs(prediction - target)
            model_info['performance_history'].append(error)
            
            # Keep only last 100 performance records
            if len(model_info['performance_history']) > 100:
                model_info['performance_history'] = model_info['performance_history'][-100:]
            
            if len(model_info['performance_history']) % 10 == 0:
                avg_error = np.mean(model_info['performance_history'][-10:])
                self.logger.info(f"Online model {symbol} - Average error: {avg_error:.3f}")
            
        except Exception as e:
            self.logger.error(f"L·ªói c·∫≠p nh·∫≠t online model cho {symbol}: {e}")
    
    def get_prediction(self, symbol: str, features: np.ndarray) -> Tuple[float, float]:
        """L·∫•y prediction t·ª´ online model"""
        
        try:
            if symbol not in self.online_models:
                return 0.0, 0.0
            
            model_info = self.online_models[symbol]
            
            # Convert numpy array to dict for River framework
            features_dict = self._numpy_to_dict(features)
            if model_info['preprocessor'] is None:
                self.logger.warning(f"Preprocessor is None for {symbol}, returning default prediction")
                return 0.0
            
            try:
                scaled_features = model_info['preprocessor'].transform_one(features_dict)
            except Exception as e:
                self.logger.warning(f"Could not transform features for {symbol}: {e}. Model not yet initialized.")
                return 0.0
            
            prediction = model_info['linear_model'].predict_one(scaled_features)
            confidence = 1.0 - np.mean(model_info['performance_history'][-10:]) if model_info['performance_history'] else 0.5
            
            return prediction, min(confidence, 1.0)
            
        except Exception as e:
            self.logger.error(f"L·ªói prediction t·ª´ online model {symbol}: {e}")
            return 0.0, 0.0
    
    def detect_anomaly(self, symbol: str, features: np.ndarray) -> bool:
        """Ph√°t hi·ªán anomaly trong data"""
        
        try:
            if symbol not in self.online_models:
                return False
            
            model_info = self.online_models[symbol]
            if model_info['preprocessor'] is None:
                self.logger.warning(f"Preprocessor is None for {symbol}, returning no anomaly")
                return False
            
            try:
                scaled_features = model_info['preprocessor'].transform_one(features)
            except Exception as e:
                self.logger.warning(f"Could not transform features for {symbol}: {e}. Model not yet initialized.")
                return False
            
            # Check if current data is anomaly
            anomaly_score = model_info['anomaly_detector'].score_one(scaled_features)
            
            # Threshold for anomaly detection (adjust based on domain knowledge)
            return anomaly_score < -1.0  # Negative score indicates anomaly
            
        except Exception as e:
            self.logger.error(f"L·ªói anomaly detection cho {symbol}: {e}")
            return False

class AutoRetrainManager:
    """Qu·∫£n l√Ω t·ª± ƒë·ªông retrain models khi c√≥ drift ho·∫∑c performance gi·∫£m"""
    
    def __init__(self, ensemble_model: EnsembleModel, lstm_model: LSTMModel):
        self.ensemble_model = ensemble_model
        self.lstm_model = lstm_model
        self.drift_detector = ConceptDriftDetector()
        self.online_manager = OnlineLearningManager()
        self.logger = LOG_MANAGER.get_logger('AutoRetrainManager')
        
        # Performance tracking
        self.performance_history = {
            'ensemble': [],
            'lstm': [],
            'overall': []
        }
        self.last_retrain_time = datetime.now()
        self.retrain_threshold = 0.05  # Retrain n·∫øu performance gi·∫£m >5%
        
        # Model versions v√† backup
        self.model_versions = 0
        self.model_backups = {}
    
    def evaluate_model_performance(self, models_data: Dict[str, Dict]) -> Dict[str, float]:
        """ƒê√°nh gi√° performance hi·ªán t·∫°i c·ªßa models"""
        
        performance_metrics = {
            'ensemble_accuracy': 0.0,
            'lstm_accuracy': 0.0,
            'overall_performance': 0.0,
            'performance_trend': 'stable'
        }
        
        try:
            # Simulate model evaluation (trong th·ª±c t·∫ø s·∫Ω c√≥ real data)
            performance_metrics['ensemble_accuracy'] = np.random.uniform(0.6, 0.8)
            performance_metrics['lstm_accuracy'] = np.random.uniform(0.6, 0.9)
            
            # Overall performance l√† weighted average
            performance_metrics['overall_performance'] = (
                0.6 * performance_metrics['ensemble_accuracy'] + 
                0.4 * performance_metrics['lstm_accuracy']
            )
            
            # Track performance history
            self.performance_history['ensemble'].append(performance_metrics['ensemble_accuracy'])
            self.performance_history['lstm'].append(performance_metrics['lstm_accuracy'])
            self.performance_history['overall'].append(performance_metrics['overall_performance'])
            
            # Keep only last 50 records
            for key in self.performance_history:
                if len(self.performance_history[key]) > 50:
                    self.performance_history[key] = self.performance_history[key][-50:]
            
            # Calculate performance trend
            if len(self.performance_history['overall']) >= 10:
                recent_avg = np.mean(self.performance_history['overall'][-5:])
                older_avg = np.mean(self.performance_history['overall'][-10:-5])
                
                if recent_avg > older_avg + 0.02:
                    performance_metrics['performance_trend'] = 'improving'
                elif recent_avg < older_avg - 0.02:
                    performance_metrics['performance_trend'] = 'declining'
                else:
                    performance_metrics['performance_trend'] = 'stable'
            
            self.logger.info(f"Model Performance - Overall: {performance_metrics['overall_performance']:.3f}, "
                            f"Trend: {performance_metrics['performance_trend']}")
            
        except Exception as e:
            self.logger.error(f"L·ªói ƒë√°nh gi√° performance: {e}")
        
        return performance_metrics
    
    def check_retrain_conditions(self, new_data: pd.DataFrame) -> Dict[str, bool]:
        """Ki·ªÉm tra ƒëi·ªÅu ki·ªán c·∫ßn retrain models"""
        
        retrain_conditions = {
            'performance_decline': False,
            'concept_drift': False,
            'time_based': False,
            'should_retrain': False
        }
        
        try:
            # 1. Check performance decline
            if len(self.performance_history['overall']) >= 10:
                recent_performance = np.mean(self.performance_history['overall'][-5:])
                historical_performance = np.mean(self.performance_history['overall'][-10:-5])
                
                performance_drop = historical_performance - recent_performance
                retrain_conditions['performance_decline'] = performance_drop > self.retrain_threshold
            
            # 2. Check concept drift
            np_data = new_data.select_dtypes(include=[np.number]).values
            drift_results = self.drift_detector.detect_drift(np_data)
            retrain_conditions['concept_drift'] = drift_results['overall_drift']
            
            # 3. Check time-based retraining (m·ªói 24h)
            hours_since_last_retrain = (datetime.now() - self.last_retrain_time).total_seconds() / 3600
            retrain_conditions['time_based'] = hours_since_last_retrain > 24
            
            # 4. Overall decision
            retrain_conditions['should_retrain'] = (
                retrain_conditions['performance_decline'] or 
                retrain_conditions['concept_drift'] or 
                retrain_conditions['time_based']
            )
            
            if retrain_conditions['should_retrain']:
                self.logger.warning(f"Retrain conditions met - "
                                  f"Performance: {retrain_conditions['performance_decline']}, "
                                  f"Drift: {retrain_conditions['concept_drift']}, "
                                  f"Time: {retrain_conditions['time_based']}")
            
        except Exception as e:
            self.logger.error(f"L·ªói ki·ªÉm tra retrain conditions: {e}")
        
        return retrain_conditions
    
    def execute_retrain(self, X_train: pd.DataFrame, y_train: pd.Series, 
                       symbol: str = "ALL") -> Dict[str, Any]:
        """Th·ª±c hi·ªán retrain models"""
        
        retrain_results = {
            'retrain_success': False,
            'new_accuracy': 0.0,
            'improvement': 0.0,
            'models_updated': [],
            'retain_time': datetime.now().isoformat()
        }
        
        try:
            self.logger.info(f"B·∫Øt ƒë·∫ßu retrain cho {symbol}")
            
            # Backup current models
            self.model_versions += 1
            backup_key = f"version_{self.model_versions}_{symbol}"
            
            if hasattr(self.ensemble_model, 'models'):
                self.model_backups[backup_key] = self.ensemble_model.models.copy()
            
            # Store old performance for comparison
            old_performance = np.mean(self.performance_history['overall'][-5:]) if self.performance_history['overall'] else 0.0
            
            # Retrain ensemble model
            try:
                ensemble_scores = self.ensemble_model.train_ensemble(X_train, y_train)
                retrain_results['models_updated'].append('ensemble')
                self.logger.info(f"Ensemble retrain completed - F1: {ensemble_scores.get('f1', 0):.3f}")
            except Exception as e:
                self.logger.error(f"L·ªói retrain ensemble: {e}")
            
            # Retrain LSTM model
            try:
                lstm_scores = self.lstm_model.train(X_train, y_train)
                retrain_results['models_updated'].append('lstm')
                self.logger.info(f"LSTM retrain completed - Val Acc: {lstm_scores.get('val_accuracy', 0):.3f}")
            except Exception as e:
                self.logger.error(f"L·ªói retrain LSTM: {e}")
            
            # Update performance tracking
            if retrain_results['models_updated']:
                new_performance = np.max([
                    ensemble_scores.get('f1', 0), 
                    lstm_scores.get('val_accuracy', 0)
                ])
                
                retrain_results['new_accuracy'] = new_performance
                retrain_results['improvement'] = new_performance - old_performance
                
                # Update history
                self.performance_history['ensemble'].append(ensemble_scores.get('f1', 0))
                self.performance_history['lstm'].append(lstm_scores.get('val_accuracy', 0))
                self.performance_history['overall'].append(new_performance)
                
                self.last_retrain_time = datetime.now()
                retrain_results['retrain_success'] = True
                
                self.logger.info(f"Retrain completed - Improvement: {retrain_results['improvement']:.3f}")
                
                # N·∫øu improved performance ƒë√°ng k·ªÉ, remove old backup
                if retrain_results['improvement'] > 0.02:
                    old_backups_to_remove = [k for k in self.model_backups.keys() if backup_key in k and k != backup_key]
                    for old_backup in old_backups_to_remove[-3:]:  # Keep only 3 most recent backups
                        del self.model_backups[old_backup]
            
        except Exception as e:
            self.logger.error(f"L·ªói trong retrain process: {e}")
        
        return retrain_results
    
    def get_model_diagnostics(self) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin diagnostics v·ªÅ models"""
        
        diagnostics = {
            'performance_history': {
                'ensemble_mean': np.mean(self.performance_history['ensemble']) if self.performance_history['ensemble'] else 0,
                'lstm_mean': np.mean(self.performance_history['lstm']) if self.performance_history['lstm'] else 0,
                'overall_mean': np.mean(self.performance_history['overall']) if self.performance_history['overall'] else 0,
                'overall_trend': 'not_enough_data'
            },
            'drift_status': {
                'drift_detected': self.drift_detector.drift_detected,
                'total_drifts': 0
            },
            'retrain_info': {
                'version_count': self.model_versions,
                'last_retrain': self.last_retrain_time.isoformat(),
                'hours_since_retrain': (datetime.now() - self.last_retrain_time).total_seconds() / 3600
            },
            'online_models': {}
        }
        
        # Performance trend analysis
        if len(self.performance_history['overall']) >= 5:
            recent_points = self.performance_history['overall'][-5:]
            slope = np.polyfit(range(len(recent_points)), recent_points, 1)[-1]
            
            if slope > 0.005:
                diagnostics['performance_history']['overall_trend'] = 'improving'
            elif slope < -0.005:
                diagnostics['performance_history']['overall_trend'] = 'declining'
            else:
                diagnostics['performance_history']['overall_trend'] = 'stable'
        
        # Online model diagnostics
        for symbol in Config.SYMBOLS:
            if symbol in self.online_manager.online_models:
                model_info = self.online_manager.online_models[symbol]
                diagnostics['online_models'][symbol] = {
                    'performance_record_count': len(model_info['performance_history']),
                    'recent_average_error': np.mean(model_info['performance_history'][-10:]) if model_info['performance_history'] else 0
                }
        
        return diagnostics# ===== OBSERVABILITY V√Ä DISCORD NOTIFICATIONS =====
class DiscordNotificationManager:
    """Qu·∫£n l√Ω th√¥ng b√°o Discord v·ªõi rich embeds"""
    
    def __init__(self):
        self.webhook_url = Config.DISCORD_WEBHOOK
        self.logger = LOG_MANAGER.get_logger('Discord')
        self.notification_queue = queue.Queue()
        self.rate_limit_delay = 1  # seconds between notifications
    
    async def send_signal_notification(self, symbol: str, signal_data: Dict[str, Any]):
        """G·ª≠i th√¥ng b√°o signal m·ªõi"""
        
        embed_data = {
            "title": f"üö® New Trading Signal - {symbol}",
            "color": 0x00ff00 if signal_data.get('action_type') == 'buy' else 0xff0000,
            "fields": [
                {"name": "Action", "value": signal_data['action_type'].upper(), "inline": True},
                {"name": "Signal Strength", "value": f"{signal_data.get('signal_strength', 0):.2f}", "inline": True},
                {"name": "Confidence", "value": f"{signal_data.get('confidence', 0):.2f}", "inline": True},
                {"name": "Market Regime", "value": signal_data.get('market_regime', 'unknown'), "inline": True},
                {"name": "Reason", "value": signal_data.get('decision_reason', 'No reason provided'), "inline": False}
            ],
            "timestamp": datetime.now().isoformat(),
            "footer": {"text": "Trading Bot AI/ML"}
        }
        
        await self._send_embed(embed_data)
    
    async def send_position_opened(self, symbol: str, position_data: Dict[str, Any]):
        """G·ª≠i th√¥ng b√°o m·ªü position"""
        
        embed_data = {
            "title": f"üü¢ Position Opened - {symbol}",
            "color": 0x00ff00,
            "fields": [
                {"name": "Symbol", "value": symbol, "inline": True},
                {"name": "Size", "value": f"{position_data.get('size', 0):.2f}", "inline": True},
                {"name": "Entry Price", "value": f"{position_data.get('entry_price', 0):.4f}", "inline": True},
                {"name": "Stop Loss", "value": f"{position_data.get('stop_loss', 0):.4f}", "inline": True},
                {"name": "Take Profit", "value": f"{position_data.get('take_profit', 0):.4f}", "inline": True},
                {"name": "Risk", "value": f"{position_data.get('risk_percentage', 0):.1f}%", "inline": True}
            ],
            "timestamp": datetime.now().isoformat(),
            "footer": {"text": "Position Management"}
        }
        
        await self._send_embed(embed_data)
    
    async def send_position_closed(self, symbol: str, profit_loss: float, return_percentage: float):
        """G·ª≠i th√¥ng b√°o ƒë√≥ng position"""
        
        emoji = "üìà" if profit_loss >= 0 else "üìâ"
        color = 0x00ff00 if profit_loss >= 0 else 0xff0000
        
        embed_data = {
            "title": f"{emoji} Position Closed - {symbol}",
            "color": color,
            "fields": [
                {"name": "Symbol", "value": symbol, "inline": True},
                {"name": "PnL", "value": f"${profit_loss:.2f}", "inline": True},
                {"name": "Return %", "value": f"{return_percentage:.2f}%", "inline": True},
                {"name": "Result", "value": "PROFIT" if profit_loss >= 0 else "LOSS", "inline": True}
            ],
            "timestamp": datetime.now().isoformat(),
            "footer": {"text": "Trade Result"}
        }
        
        await self._send_embed(embed_data)
    
    async def send_error_notification(self, error_type: str, error_message: str, symbol: str = ""):
        """G·ª≠i th√¥ng b√°o l·ªói h·ªá th·ªëng"""
        
        title_suffix = f" - {symbol}" if symbol else ""
        
        embed_data = {
            "title": f"‚ö†Ô∏è Error Alert{title_suffix}",
            "color": 0xff8800,
            "fields": [
                {"name": "Error Type", "value": error_type, "inline": True},
                {"name": "Message", "value": error_message[:1000], "inline": False},
                {"name": "Time", "value": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "inline": True}
            ],
            "timestamp": datetime.now().isoformat(),
            "footer": {"text": "System Alert"}
        }
        
        await self._send_embed(embed_data)
    
    async def send_performance_report(self, metrics: Dict[str, float], model_performance: Dict[str, Any]):
        """G·ª≠i b√°o c√°o hi·ªáu su·∫•t"""
        
        embed_data = {
            "title": "üìä Daily Performance Report",
            "color": 0x0099ff,
            "fields": [
                {"name": "Portfolio Value", "value": f"${metrics.get('total_value', 0):,.2f}", "inline": True},
                {"name": "Daily P&L", "value": f"${metrics.get('daily_pnl', 0):,.2f}", "inline": True},
                {"name": "Daily Return", "value": f"{metrics.get('daily_return', 0):.2f}%", "inline": True},
                {"name": "Sharpe Ratio", "value": f"{metrics.get('sharpe_ratio', 0):.3f}", "inline": True},
                {"name": "Max Drawdown", "value": f"{metrics.get('max_drawdown', 0):.2f}%", "inline": True},
                {"name": "Model Performance", "value": f"{model_performance.get('overall_performance', 0):.3f}", "inline": True}
            ],
            "timestamp": datetime.now().isoformat(),
            "footer": {"text": "Trading Bot Performance"}
        }
        
        await self._send_embed(embed_data)
    
    async def _send_embed(self, embed_data: Dict[str, Any]):
        """G·ª≠i embed message t·ªõi Discord webhook"""
        
        try:
            payload = {"embeds": [embed_data]}
            
            async with aiohttp.ClientSession() as session:
                async with session.post(self.webhook_url, json=payload) as response:
                    if response.status == 204:  # Discord webhook success
                        self.logger.info("Discord notification sent successfully")
                    else:
                        self.logger.warning(f"Discord notification failed: {response.status}")
                        
        except Exception as e:
            self.logger.error(f"L·ªói g·ª≠i Discord notification: {e}")
        
        # Rate limiting
        await asyncio.sleep(self.rate_limit_delay)

class AdvancedRiskManager:
    """Advanced Risk Management System"""
    
    def __init__(self, api_manager):
        self.api_manager = api_manager
        self.logger = LOG_MANAGER.get_logger('RiskManager')
        
        # Portfolio settings
        self.max_total_exposure = 1.0  # 100% of portfolio
        self.max_position_size = 0.1   # 10% per position
        self.stop_loss_pct = 0.02      # 2% stop loss
        self.take_profit_ratio = 2.0   # 2:1 risk/reward
        
        # Position tracking
        self.open_positions = {}
        self.portfolio_value = 10000   # Starting portfolio value
        self.cash_balance = 10000      # Available cash
        
    def calculate_position_size(self, symbol: str, signal_strength: float, confidence: float, entry_price: float) -> Dict[str, Any]:
        """Calculate optimal position size based on risk parameters"""
        
        # Base position size calculation
        base_size = self.cash_balance * self.max_position_size
        
        # Adjust based on signal strength and confidence
        adjustment_factor = min(signal_strength * confidence, 1.0)
        position_size = base_size * adjustment_factor
        
        # Calculate stop loss and take profit
        stop_loss = entry_price * (1 - self.stop_loss_pct)
        take_profit = entry_price + (entry_price - stop_loss) * self.take_profit_ratio
        
        # Calculate risk percentage
        risk_amount = abs(position_size * (entry_price - stop_loss) / entry_price)
        risk_percentage = (risk_amount / self.portfolio_value) * 100
        
        return {
            'size': position_size,
            'entry_price': entry_price,
            'stop_loss': stop_loss,
            'take_profit': take_profit,
            'risk_percentage': risk_percentage,
            'risk_amount': risk_amount
        }
    
    def validate_trade(self, symbol: str, position_data: Dict[str, Any]) -> bool:
        """Validate if trade meets risk criteria"""
        
        # Check if we already have a position in this symbol
        if symbol in self.open_positions:
            self.logger.warning(f"Already have position in {symbol}")
            return False
            
        # Check portfolio exposure
        current_exposure = self._calculate_portfolio_exposure()
        new_exposure = position_data.get('risk_amount', 0)
        
        if current_exposure + new_exposure > self.max_total_exposure * self.portfolio_value:
            self.logger.warning(f"Trade rejected: Portfolio exposure too high ({current_exposure + new_exposure:.2f})")
            return False
            
        # Check available cash
        if position_data.get('size', 0) > self.cash_balance:
            self.logger.warning(f"Trade rejected: Insufficient cash ({self.cash_balance:.2f})")
            return False
            
        return True
    
    def update_position(self, symbol: str, position_data: Dict[str, Any]):
        """Update position tracking"""
        
        position_data.update({
            'status': 'open',
            'timestamp': datetime.now(),
            'symbol': symbol
        })
        
        self.open_positions[symbol] = position_data
        
        # Update cash balance
        self.cash_balance -= position_data.get('size', 0)
        
        # Insert into database
        try:
            import sqlite3
            
            conn = sqlite3.connect(Config.DB_PATH)
            cursor = conn.cursor()
            
            # Determine position type from the data
            position_type = 'buy' if position_data.get('position_type', 'buy') == 'buy' else 'sell'
            
            # Insert new position record
            cursor.execute("""
                INSERT INTO positions (
                    symbol, status, position_type, size, entry_price, 
                    stop_loss, take_profit, entry_time, risk_percentage
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                symbol,
                'open',
                position_type,
                position_data.get('size', 0),
                position_data.get('entry_price', 0),
                position_data.get('stop_loss'),
                position_data.get('take_profit'),
                datetime.now().isoformat(),
                position_data.get('risk_percentage', 0)
            ))
            
            # Get the ID of the newly created record
            position_id = cursor.lastrowid
            
            # Store the position ID in the position data for future reference
            position_data['db_id'] = position_id
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"‚úÖ Position entered into database with ID {position_id} for {symbol}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to insert position into database for {symbol}: {e}")
        
        self.logger.info(f"Position updated for {symbol}: {position_data}")
    
    def close_position(self, symbol: str, exit_price: float):
        """Close position and update portfolio"""
        
        if symbol not in self.open_positions:
            self.logger.warning(f"No position found for {symbol}")
            return None
            
        position = self.open_positions[symbol]
        
        # Calculate P&L
        entry_price = position.get('entry_price', exit_price)
        position_size = position.get('size', 0)
        
        pnl = position_size * (exit_price - entry_price) / entry_price
        
        # Update portfolio
        self.portfolio_value += pnl
        self.cash_balance += position_size + pnl
        
        # Remove from open positions
        closed_position = self.open_positions.pop(symbol)
        closed_position.update({
            'status': 'closed',
            'exit_price': exit_price,
            'pnl': pnl,
            'close_timestamp': datetime.now()
        })
        
        self.logger.info(f"Position closed for {symbol}: P&L = {pnl:.2f}")
        return closed_position
    
    def calculate_portfolio_metrics(self) -> Dict[str, Any]:
        """Calculate current portfolio metrics"""
        
        total_open_pnl = 0
        total_unrealized_pnl = 0
        for symbol, position in self.open_positions.items():
            if position.get('status') == 'open':
                # Simple current P&L calculation (would need current price in real implementation)
                entry_price = position.get('entry_price', 0)
                current_price = position.get('current_price', entry_price)
                position_size = position.get('position_size', 0)
                
                # Calculate P&L based on position type
                if position.get('side') == 'buy':
                    unrealized_pnl = (current_price - entry_price) * position_size
                else:  # sell
                    unrealized_pnl = (entry_price - current_price) * position_size
                
                total_open_pnl += unrealized_pnl
                total_unrealized_pnl += unrealized_pnl
        
        # Calculate max drawdown (simplified)
        current_value = self.portfolio_value + total_open_pnl
        if not hasattr(self, '_peak_value') or current_value > self._peak_value:
            self._peak_value = current_value
        
        max_drawdown = (self._peak_value - current_value) / self._peak_value if self._peak_value > 0 else 0
        
        return {
            'total_value': current_value,
            'total_pnl': total_open_pnl,  # Add missing total_pnl key
            'cash_balance': self.cash_balance,
            'open_positions': len([p for p in self.open_positions.values() if p.get('status') == 'open']),
            'total_exposure': self._calculate_portfolio_exposure(),
            'unrealized_pnl': total_unrealized_pnl,
            'max_drawdown': max_drawdown
        }
    
    def _calculate_portfolio_exposure(self) -> float:
        """Calculate current portfolio exposure"""
        
        total_exposure = 0
        for position in self.open_positions.values():
            if position.get('status') == 'open':
                total_exposure += position.get('size', 0)
        
        return total_exposure / self.portfolio_value if self.portfolio_value > 0 else 0
    
    def get_position_status(self, symbol: str) -> Dict[str, Any]:
        """Get current status of a position"""
        
        if symbol in self.open_positions:
            return self.open_positions[symbol]
        return None

class RealTimeMonitor:
    """Gi√°m s√°t real-time c√°c positions v√† t·ª± ƒë·ªông ƒë√≥ng SL/TP"""
    
    def __init__(self, risk_manager: AdvancedRiskManager):
        self.risk_manager = risk_manager
        self.discord_manager = DiscordNotificationManager()
        self.logger = LOG_MANAGER.get_logger('RiskManager')
        self.monitoring_active = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """B·∫Øt ƒë·∫ßu gi√°m s√°t real-time"""
        
        if self.monitoring_active:
            self.logger.warning("Monitoring already active")
            return
        
        self.monitoring_active = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        self.logger.info("Real-time monitoring started")
    
    def stop_monitoring(self):
        """D·ª´ng gi√°m s√°t"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        
        self.logger.info("Real-time monitoring stopped")
    
    def _monitor_loop(self):
        """V√≤ng l·∫∑p gi√°m s√°t ch√≠nh"""
        
        while self.monitoring_active:
            try:
                # Monitor positions every 30 seconds
                time.sleep(30)
                
                if not self.risk_manager.open_positions:
                    continue
                
                # Check each open position
                positions_to_close = []
                
                for symbol, position in self.risk_manager.open_positions.items():
                    if position['status'] != 'open':
                        continue
                    
                    current_price = position['current_price']
                    stop_loss = position.get('stop_loss')
                    take_profit = position.get('take_profit')
                    
                    # Check stop loss and take profit
                    pnl = position['size'] * (current_price - position['entry_price'])
                    
                    # SL/TP logic
                    should_close = False
                    close_reason = ""
                    
                    if stop_loss:
                        if position['size'] > 0 and current_price <= stop_loss:  # Long position hit SL
                            should_close = True
                            close_reason = "Stop Loss"
                        elif position['size'] < 0 and current_price >= stop_loss:  # Short position hit SL
                            should_close = True
                            close_reason = "Stop Loss"
                    
                    if take_profit and not should_close:
                        if position['size'] > 0 and current_price >= take_profit:  # Long position hit TP
                            should_close = True
                            close_reason = "Take Profit"
                        elif position['size'] < 0 and current_price <= take_profit:  # Short position hit TP
                            should_close = True
                            close_reason = "Take Profit"
                    
                    # Weekend closure for non-crypto - now handled by MarketStatusChecker
                    # This logic has been moved to the main trading cycle
                    
                    if should_close:
                        positions_to_close.append({
                            'symbol': symbol,
                            'current_pnl': pnl,
                            'return_percentage': (current_price / position['entry_price'] - 1) * 100,
                            'reason': close_reason
                        })
                
                # Execute closures
                for close_info in positions_to_close:
                    self._close_position(close_info)
                
            except Exception as e:
                self.logger.error(f"L·ªói trong monitoring loop: {e}")
    
    def _close_position(self, close_info: Dict[str, Any]):
        """ƒê√≥ng position v√† g·ª≠i notification"""
        
        symbol = close_info['symbol']
        pnl = close_info['current_pnl']
        return_pct = close_info['return_percentage']
        reason = close_info['reason']
        
        try:
            # Update position status
            position = self.risk_manager.open_positions[symbol]
            position['status'] = 'closed'
            position['pnl'] = pnl
            position['exit_time'] = datetime.now()
            
            # Calculate exit price from P&L
            entry_price = position.get('entry_price', 0)
            position_size = position.get('size', 0)
            exit_price = None
            
            if position_size != 0 and entry_price != 0:
                # exit_price = entry_price + (pnl / position_size)
                exit_price = entry_price + (pnl / abs(position_size)) * (1 if position_size > 0 else -1)
                position['exit_price'] = exit_price
            
            # Save to database
            import sqlite3
            
            conn = sqlite3.connect(Config.DB_PATH)
            cursor = conn.cursor()
            
            # Use database ID if available, otherwise fallback to symbol lookup
            position_id = position.get('db_id')
            
            if position_id:
                cursor.execute("""
                    UPDATE positions 
                    SET status='closed', exit_time=?, pnl=?, exit_price=? 
                    WHERE id=?
                """, (datetime.now().isoformat(), pnl, exit_price, position_id))
                
                self.logger.info(f"‚úÖ Position updated in database using ID {position_id}")
            else:
                # Fallback to symbol-based update for backward compatibility
                cursor.execute("""
                    UPDATE positions 
                    SET status='closed', exit_time=?, pnl=?, exit_price=? 
                    WHERE symbol=? AND status='open'
                """, (datetime.now().isoformat(), pnl, exit_price, symbol))
                
                # Get the ID of the updated record for future reference
                cursor.execute("SELECT id FROM positions WHERE symbol=? AND status='closed' ORDER BY id DESC LIMIT 1", (symbol,))
                result = cursor.fetchone()
                if result:
                    position['db_id'] = result[0]
                
                self.logger.info(f"‚úÖ Position updated in database using symbol {symbol}")
            
            conn.commit()
            conn.close()
            
            # Send Discord notification
            asyncio.run(self.discord_manager.send_position_closed(symbol, pnl, return_pct))
            
            self.logger.info(f"Position closed: {symbol} - PnL: ${pnl:.2f} ({return_pct:.2f}%) - Reason: {reason}")
            
        except Exception as e:
            self.logger.error(f"L·ªói ƒë√≥ng position {symbol}: {e}")
    

# ===== MARKET STATUS CHECKER =====
class MarketStatusChecker:
    """Ki·ªÉm tra tr·∫°ng th√°i m·ªü/ƒë√≥ng c·ª≠a c·ªßa c√°c th·ªã tr∆∞·ªùng"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('MarketStatusChecker')
        
        # Import pandas_market_calendars
        try:
            import pandas_market_calendars as pmc
            self.pmc = pmc
        except ImportError:
            self.logger.error("pandas_market_calendars not installed. Please install it: pip install pandas_market_calendars")
            raise ImportError("pandas_market_calendars is required for market hours checking")
        
        # Initialize market calendars
        self.calendars = {}
        self.symbol_to_calendar = {}
        
        try:
            # Initialize calendars for different markets
            self.calendars['NYSE'] = pmc.get_calendar('NYSE')
            self.calendars['NASDAQ'] = pmc.get_calendar('NASDAQ')
            
            # Map symbols to their respective calendars
            self.symbol_to_calendar = {
                'NAS100': self.calendars['NYSE'],  # NAS100 follows NYSE hours
                'EURUSD': None,  # Forex - handled separately
                'XAUUSD': None,  # Gold - handled separately  
                'BTCUSD': None   # Crypto - 24/7
            }
            
            self.logger.info("‚úÖ Market calendars initialized successfully")
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to initialize market calendars: {e}")
            raise
    
    def is_market_open(self, symbol: str) -> bool:
        """Ki·ªÉm tra th·ªã tr∆∞·ªùng c√≥ m·ªü c·ª≠a kh√¥ng cho symbol c·ª• th·ªÉ"""
        
        try:
            now_utc = pd.Timestamp.utcnow()
            
            # Handle crypto (24/7 trading)
            if symbol == 'BTCUSD':
                return True
            
            # Handle Forex markets (EURUSD, XAUUSD)
            if symbol in ['EURUSD', 'XAUUSD']:
                return self._is_forex_market_open(now_utc)
            
            # Handle exchange-traded instruments (NAS100)
            if symbol in self.symbol_to_calendar:
                calendar = self.symbol_to_calendar[symbol]
                if calendar is None:
                    # Fallback to forex logic for unmapped symbols
                    return self._is_forex_market_open(now_utc)
                
                # CRITICAL FIX: Use robust schedule-based logic instead of is_open_on_minute
                try:
                    # Get schedule for today in UTC
                    schedule = calendar.schedule(start_date=now_utc.date(), end_date=now_utc.date())
                    
                    # If schedule is empty, today is not a trading day (holiday, weekend)
                    if schedule.empty:
                        return False
                    
                    # Get market open and close times
                    market_open = schedule.iloc[0]['market_open']
                    market_close = schedule.iloc[0]['market_close']
                    
                    # Check if current time is within market hours
                    return market_open <= now_utc < market_close
                    
                except Exception as schedule_error:
                    self.logger.warning(f"Schedule check failed for {symbol}: {schedule_error}")
                    # Fallback to forex logic on error
                    return self._is_forex_market_open(now_utc)
            
            # Default fallback
            self.logger.warning(f"Unknown symbol {symbol}, using forex logic")
            return self._is_forex_market_open(now_utc)
            
        except Exception as e:
            self.logger.error(f"Error checking market status for {symbol}: {e}")
            # Default to closed on error for safety
            return False
    
    def _is_forex_market_open(self, now_utc: pd.Timestamp) -> bool:
        """Ki·ªÉm tra th·ªã tr∆∞·ªùng Forex c√≥ m·ªü c·ª≠a kh√¥ng"""
        
        weekday = now_utc.weekday()  # 0=Monday, 6=Sunday
        hour = now_utc.hour
        
        # Forex market logic:
        # - Closed from Friday 21:00 UTC to Sunday 21:00 UTC
        # - Open Monday 00:00 UTC to Friday 21:00 UTC
        
        if weekday == 4:  # Friday
            return hour < 21  # Open until 21:00 UTC Friday
        elif weekday == 5:  # Saturday
            return False  # Always closed
        elif weekday == 6:  # Sunday
            return hour >= 21  # Open from 21:00 UTC Sunday
        else:  # Monday to Thursday
            return True  # Always open
    
    def get_market_status_summary(self) -> Dict[str, bool]:
        """L·∫•y tr·∫°ng th√°i c·ªßa t·∫•t c·∫£ c√°c th·ªã tr∆∞·ªùng"""
        
        status = {}
        for symbol in Config.SYMBOLS:
            status[symbol] = self.is_market_open(symbol)
        
        return status

# ===== MAIN TRADING BOT CONTROLLER =====
class TradingBotController:
    """Controller ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô h·ªá th·ªëng bot"""
    
    def __init__(self):
        self.logger = LOG_MANAGER.get_logger('BotCore')
        self.running = False
        
        # Initialize core components
        self.api_manager = None
        self.data_manager = None
        self.feature_engineer = AdvancedFeatureEngineer()
        self.news_manager = None
        
        # ML Models
        self.ensemble_model = EnsembleModel()
        self.lstm_model = LSTMModel()
        self.auto_retrain_manager = None
        self.rl_agent = None
        
        # Trading Components
        self.trend_agent = TrendSpecialistAgent()
        self.news_agent = None
        self.risk_agent = RiskSpecialistAgent()
        self.master_agent = None
        self.risk_manager = None
        self.real_time_monitor = None
        
        # Observability
        self.discord_manager = DiscordNotificationManager()
        
        # Market Status Checker
        self.market_checker = None
        
        # Performance tracking
        self.cycle_count = 0
        self.last_data_fetch = None
        self.trading_session_start = None
    
    def setup_database(self):
        """Kh·ªüi t·∫°o SQLite database v√† t·∫°o b·∫£ng positions n·∫øu ch∆∞a t·ªìn t·∫°i"""
        
        try:
            import sqlite3
            
            conn = sqlite3.connect(Config.DB_PATH)
            cursor = conn.cursor()
            
            # T·∫°o b·∫£ng positions v·ªõi c·∫•u tr√∫c ho√†n ch·ªânh
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS positions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    status TEXT NOT NULL,
                    position_type TEXT NOT NULL,
                    size REAL NOT NULL,
                    entry_price REAL NOT NULL,
                    exit_price REAL,
                    stop_loss REAL,
                    take_profit REAL,
                    entry_time TEXT NOT NULL,
                    exit_time TEXT,
                    pnl REAL,
                    risk_percentage REAL
                )
            """)
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"‚úÖ Database initialized at {Config.DB_PATH}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Database initialization failed: {e}")
            raise
    
    async def initialize(self):
        """Kh·ªüi t·∫°o t·∫•t c·∫£ components"""
        
        try:
            self.logger.info("üöÄ Initializing Trading Bot...")
            
            # Setup database first
            self.setup_database()
            
            # Initialize API Manager first
            self.api_manager = APIManager()
            
            # Restore open positions from database
            try:
                conn = sqlite3.connect(Config.DB_PATH)
                cursor = conn.cursor()
                
                # Query all open positions from database
                cursor.execute("""
                    SELECT id, symbol, status, position_type, size, entry_price, 
                           stop_loss, take_profit, entry_time, risk_percentage
                    FROM positions 
                    WHERE status = 'open'
                """)
                
                open_positions = cursor.fetchall()
                conn.close()
                
                # Initialize risk_manager to store positions
                self.risk_manager = AdvancedRiskManager(self.api_manager)
                
                # Restore each position
                restored_count = 0
                for row in open_positions:
                    db_id, symbol, status, position_type, size, entry_price, stop_loss, take_profit, entry_time, risk_percentage = row
                    
                    # Recreate position_data dictionary with same structure as when position was opened
                    position_data = {
                        'db_id': db_id,
                        'symbol': symbol,
                        'status': status,
                        'position_type': position_type,
                        'size': size,
                        'entry_price': entry_price,
                        'stop_loss': stop_loss,
                        'take_profit': take_profit,
                        'entry_time': entry_time,
                        'risk_percentage': risk_percentage,
                        'timestamp': datetime.now()  # Update timestamp to current time
                    }
                    
                    # Add restored position to risk manager
                    self.risk_manager.open_positions[symbol] = position_data
                    restored_count += 1
                
                if restored_count > 0:
                    self.logger.info(f"‚úÖ Loaded {restored_count} open positions from the database.")
                else:
                    self.logger.info("No open positions to load.")
                    
            except Exception as e:
                self.logger.error(f"‚ùå Failed to restore open positions from database: {e}")
                # Initialize risk_manager even if restoration fails
                self.risk_manager = AdvancedRiskManager(self.api_manager)
            
            # Initialize Data Manager
            self.data_manager = EnhancedDataManager(self.api_manager)
            
            # Initialize News Manager
            self.news_manager = NewsEconomicManager(self.api_manager)
            
            # Initialize specialist agents
            self.news_agent = NewsSpecialistAgent(self.news_manager)
            
            # Initialize Master Agent v·ªõi AI models
            self.master_agent = MasterAgent(
                self.trend_agent, 
                self.news_agent, 
                self.risk_agent,
                ensemble_model=self.ensemble_model,
                lstm_model=self.lstm_model,
                rl_agent=self.rl_agent,
                feature_engineer=self.feature_engineer
            )
            
            # Initialize Market Status Checker
            self.market_checker = MarketStatusChecker()
            
            # Initialize Auto Retrain Manager
            self.auto_retrain_manager = AutoRetrainManager(self.ensemble_model, self.lstm_model)
            
            # Initialize RL Agent
            import gymnasium as gym
            from stable_baselines3 import PPO
            
            # Create real trading environment for RL
            class RealTradingEnv(gym.Env):
                def __init__(self, data_manager, historical_data, symbol, feature_engineer):
                    super().__init__()
                    self.data_manager = data_manager
                    self.historical_data = historical_data  # DataFrame with historical data
                    self.symbol = symbol
                    self.feature_engineer = feature_engineer
                    self.logger = LOG_MANAGER.get_logger('RealTradingEnv')
                    
                    # Action space: 0=BUY, 1=SELL, 2=HOLD
                    self.action_space = gym.spaces.Discrete(3)
                    
                    # Calculate observation space based on features
                    self._calculate_observation_space()
                    
                    # Trading state
                    self.current_step = 0
                    self.max_steps = len(historical_data) - 1  # Leave one step for next price calculation
                    self.position = 0  # 0: no position, 1: long, -1: short
                    self.entry_price = 0.0
                    
                def _calculate_observation_space(self):
                    """Calculate observation space based on feature engineering"""
                    if len(self.historical_data) > 0:
                        # Create a sample with features to determine space size
                        sample_data = self.historical_data.head(10).copy()
                        features_df = self.feature_engineer.engineer_all_features(sample_data, self.symbol)
                        
                        # Get numeric features only (exclude datetime, timestamp, etc.)
                        numeric_features = features_df.select_dtypes(include=[np.number])
                        feature_count = len(numeric_features.columns)
                        
                        # Set observation space
                        self.observation_space = gym.spaces.Box(
                            low=-np.inf, 
                            high=np.inf, 
                            shape=(feature_count,), 
                            dtype=np.float32
                        )
                        self.logger.info(f"RealTradingEnv observation space: {feature_count} features")
                    else:
                        # Fallback to default size
                        self.observation_space = gym.spaces.Box(
                            low=-np.inf, 
                            high=np.inf, 
                            shape=(50,), 
                            dtype=np.float32
                        )
                
                def step(self, action):
                    """Execute action and return next observation, reward, done, info"""
                    
                    # Get current observation (features for current candle)
                    obs = self._get_current_observation()
                    
                    # Calculate reward based on action and next candle's price movement
                    reward = self._calculate_real_reward(action)
                    
                    # Update position state
                    self._update_position(action)
                    
                    # Move to next step
                    self.current_step += 1
                    done = self.current_step >= self.max_steps
                    
                    info = {
                        'symbol': self.symbol,
                        'action': action,
                        'step': self.current_step,
                        'position': self.position,
                        'entry_price': self.entry_price,
                        'reward': reward
                    }
                    
                    return obs, reward, done, info
                
                def reset(self):
                    """Reset environment to initial state"""
                    self.current_step = 0
                    self.position = 0
                    self.entry_price = 0.0
                    
                    # Return initial observation
                    return self._get_current_observation()
                
                def _get_current_observation(self):
                    """Get current observation (features for current candle)"""
                    if self.current_step >= len(self.historical_data):
                        # Return zeros if we're past the data
                        return np.zeros(self.observation_space.shape[0], dtype=np.float32)
                    
                    # Get data up to current step
                    current_data = self.historical_data.iloc[:self.current_step + 1].copy()
                    
                    # Engineer features
                    features_df = self.feature_engineer.engineer_all_features(current_data, self.symbol)
                    
                    # Get the latest row (most recent features)
                    if len(features_df) > 0:
                        latest_features = features_df.iloc[-1]
                        # Select only numeric features
                        numeric_features = latest_features.select_dtypes(include=[np.number])
                        
                        # Convert to numpy array and ensure correct size
                        obs = numeric_features.values.astype(np.float32)
                        
                        # Pad or truncate to match observation space
                        target_size = self.observation_space.shape[0]
                        if len(obs) < target_size:
                            obs = np.pad(obs, (0, target_size - len(obs)), 'constant')
                        elif len(obs) > target_size:
                            obs = obs[:target_size]
                        
                        return obs
                    else:
                        return np.zeros(self.observation_space.shape[0], dtype=np.float32)
                
                def _calculate_real_reward(self, action: int) -> float:
                    """Calculate reward based on actual price movement"""
                    
                    # Need at least 2 candles to calculate price movement
                    if self.current_step + 1 >= len(self.historical_data):
                        return 0.0
                    
                    current_price = self.historical_data.iloc[self.current_step]['close']
                    next_price = self.historical_data.iloc[self.current_step + 1]['close']
                    
                    # Calculate price change percentage
                    price_change_pct = (next_price - current_price) / current_price
                    
                    # Calculate reward based on action
                    if action == 0:  # BUY
                        reward = price_change_pct  # Profit if price goes up
                    elif action == 1:  # SELL
                        reward = -price_change_pct  # Profit if price goes down
                    else:  # HOLD
                        reward = 0.0  # No reward for holding
                    
                    # Add small penalty for frequent trading to encourage strategic decisions
                    if action != 2:  # If not HOLD
                        reward -= 0.001  # Small transaction cost
                    
                    return reward
                
                def _update_position(self, action: int):
                    """Update position state based on action"""
                    if action == 0:  # BUY
                        if self.position <= 0:  # Enter long or close short
                            self.position = 1
                            self.entry_price = self.historical_data.iloc[self.current_step]['close']
                    elif action == 1:  # SELL
                        if self.position >= 0:  # Enter short or close long
                            self.position = -1
                            self.entry_price = self.historical_data.iloc[self.current_step]['close']
                    # HOLD (action == 2) doesn't change position
            
            # Initialize RL Agent with placeholder environment
            # Real environment will be created during training with actual historical data
            self.rl_agent = None
            self.logger.info("ü§ñ RL Agent will be initialized during training with real data")
            
            # Initialize Real-time Monitor
            self.real_time_monitor = RealTimeMonitor(self.risk_manager)
            
            self.logger.info("‚úÖ Trading Bot initialized successfully")
            
            # Send startup notification
            await self._send_startup_notification()
            
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o Trading Bot: {e}")
            await self.discord_manager.send_error_notification("Initialization Error", str(e))
            raise
    
    async def _send_startup_notification(self):
        """G·ª≠i th√¥ng b√°o kh·ªüi ƒë·ªông bot"""
        
        embed_data = {
            "title": "ü§ñ Trading Bot Started",
            "description": "AI/ML Trading Bot is now active and monitoring markets",
            "color": 0x00ff00,
            "fields": [
                {"name": "Symbols", "value": ", ".join(Config.SYMBOLS), "inline": True},
                {"name": "Portfolio Value", "value": "$100,000", "inline": True},
                {"name": "Market Regime", "value": "Monitoring...", "inline": True}
            ],
            "timestamp": datetime.now().isoformat(),
            "footer": {"text": "Trading Bot System"}
        }
        
        await self.discord_manager._send_embed(embed_data)
    
    async def run_trading_cycle(self):
        """Th·ª±c hi·ªán m·ªôt chu k·ª≥ giao d·ªãch ho√†n ch·ªânh"""
        
        cycle_start_time = datetime.now()
        
        try:
            self.logger.info(f"üìà Starting trading cycle #{self.cycle_count + 1}")
            
            # 0. Check market status before proceeding
            if self.market_checker:
                market_status = self.market_checker.get_market_status_summary()
                open_markets = [symbol for symbol, is_open in market_status.items() if is_open]
                closed_markets = [symbol for symbol, is_open in market_status.items() if not is_open]
                
                self.logger.info(f"Market Status - Open: {open_markets}, Closed: {closed_markets}")
                
                # If all markets are closed, pause for 1 hour
                if not open_markets:
                    self.logger.info("üåô All markets are closed. Pausing for 1 hour.")
                    await asyncio.sleep(3600)  # Sleep for 1 hour
                    return
            
            # 1. Fetch fresh market data
            market_data = await self._fetch_all_market_data(open_markets)
            if not market_data:
                self.logger.warning("No market data available, skipping cycle")
                return
            
            # 2. Engineer features
            enriched_data = {}
            for symbol, timeframes in market_data.items():
                # Combine all timeframes into a single DataFrame for feature engineering
                combined_df = None
                for timeframe, df in timeframes.items():
                    if df is not None and hasattr(df, 'empty') and not df.empty:
                        # Add timeframe suffix to columns to avoid conflicts
                        df_with_timeframe = df.copy()
                        
                        # Normalize datetime column names - use 'datetime' consistently
                        if 'timestamp' in df_with_timeframe.columns and 'datetime' not in df_with_timeframe.columns:
                            df_with_timeframe = df_with_timeframe.rename(columns={'timestamp': 'datetime'})
                        elif 'timestamp' not in df_with_timeframe.columns and 'datetime' not in df_with_timeframe.columns:
                            # If no datetime column exists, create one from index
                            df_with_timeframe.index.name = 'datetime'
                            df_with_timeframe = df_with_timeframe.reset_index()
                        
                        df_with_timeframe.columns = [f"{col}_{timeframe}" if col not in ['datetime', 'timestamp'] else col for col in df_with_timeframe.columns]
                        
                        if combined_df is None:
                            combined_df = df_with_timeframe.copy()
                        else:
                            # Temporal alignment: align on datetime/timestamp
                            try:
                                # Ensure datetime column exists in both dataframes
                                if 'datetime' not in combined_df.columns:
                                    if 'timestamp' in combined_df.columns:
                                        combined_df = combined_df.rename(columns={'timestamp': 'datetime'})
                                    else:
                                        combined_df.index.name = 'datetime'
                                        combined_df = combined_df.reset_index()
                                
                                # Normalize datetime columns for merging - handle timezone mismatch
                                if 'datetime' in df_with_timeframe.columns:
                                    # Convert both datetime columns to UTC/naive for compatibility
                                    if isinstance(combined_df['datetime'].dtype, pd.DatetimeTZDtype):
                                        combined_df['datetime'] = combined_df['datetime'].dt.tz_localize(None)
                                    if isinstance(df_with_timeframe['datetime'].dtype, pd.DatetimeTZDtype):
                                        df_with_timeframe['datetime'] = df_with_timeframe['datetime'].dt.tz_localize(None)
                                    
                                    # Ensure both datetime columns are the same type
                                    combined_df['datetime'] = pd.to_datetime(combined_df['datetime'])
                                    df_with_timeframe['datetime'] = pd.to_datetime(df_with_timeframe['datetime'])
                                
                                combined_df = pd.merge(combined_df, df_with_timeframe, on='datetime', how='outer', suffixes=('', f'_{timeframe}'))
                            except Exception as merge_error:
                                self.logger.warning(f"Failed to merge {symbol} {timeframe} data: {merge_error}")
                                # Skip this timeframe if merge fails
                                continue
                
                if combined_df is not None and not combined_df.empty:
                    enriched_data[symbol] = self.feature_engineer.engineer_all_features(combined_df, symbol)
            
            # 3. Analyze and decide
            portfolio_status = self._get_portfolio_status()
            decision = await self.master_agent.analyze_and_decide(enriched_data, portfolio_status)
            
            # 4. Execute trades if signals are strong enough
            if decision.get('signal_strength', 0) > 0.6 and decision.get('confidence', 0) > 0.5:
                await self._execute_trading_decisions(decision, enriched_data)
            
            # 5. Update models with new data
            await self._update_models_with_new_data(enriched_data)
            
            # 6. Check for retrain conditions
            if self.cycle_count % 24 == 0:  # Every 24 cycles
                await self._check_retrain_conditions(market_data)
            
            # 7. Calculate and report performance
            if self.cycle_count % 12 == 0:  # Every 12 cycles (hourly)
                await self._report_performance()
            
            self.cycle_count += 1
            
            cycle_duration = (datetime.now() - cycle_start_time).total_seconds()
            self.logger.info(f"‚úÖ Trading cycle #{self.cycle_count} completed in {cycle_duration:.2f}s")
            
        except Exception as e:
            # Enhanced error logging for debugging
            import traceback
            error_details = f"Error: {str(e)}\nTraceback: {traceback.format_exc()}"
            self.logger.error(f"‚ùå L·ªói trong trading cycle: {error_details}")
            
            # Specifically handle datetime-related errors
            if 'datetime' in str(e).lower() or 'timestamp' in str(e).lower():
                self.logger.error("üîç Datetime-related error detected. Check DataFrame column names and datetime formats.")
            
            await self.discord_manager.send_error_notification("Trading Cycle Error", str(e))
    
    async def _fetch_all_market_data(self, symbols_to_fetch: List[str]) -> Dict[str, pd.DataFrame]:
        """L·∫•y d·ªØ li·ªáu th·ªã tr∆∞·ªùng cho c√°c symbols ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh"""
        
        market_data = {}
        
        async with self.api_manager:
            # Fetch data sequentially to avoid rate limiting
            for symbol in symbols_to_fetch:
                symbol_data = {}
                for timeframe in Config.TIME_FRAMES:
                    try:
                        # Add delay between requests to respect rate limits
                        await asyncio.sleep(1.5)  # Increased to 1.5s for better rate limit compliance
                        df = await self.data_manager.get_fresh_data(symbol, timeframe)
                        if df is not None:
                            symbol_data[timeframe] = df
                    except Exception as e:
                        self.logger.warning(f"Failed to fetch {symbol} {timeframe}: {e}")
                        continue
                
                if symbol_data:
                    market_data[symbol] = symbol_data
            
            self.last_data_fetch = datetime.now()
            self.logger.info(f"üìä Market data fetched for {len(market_data)} symbols")
        
        return market_data
    
    def _get_portfolio_status(self) -> Dict[str, Any]:
        """L·∫•y tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa portfolio"""
        
        portfolio_metrics = self.risk_manager.calculate_portfolio_metrics()
        
        return {
            'total_value': portfolio_metrics['total_value'],
            'daily_pnl': portfolio_metrics['total_pnl'],
            'total_exposure': self.risk_manager._calculate_portfolio_exposure(),
            'max_drawdown': portfolio_metrics['max_drawdown'],
            'positions_count': len([p for p in self.risk_manager.open_positions.values() if p['status'] == 'open'])
        }
    
    async def _execute_trading_decisions(self, decision: Dict[str, Any], market_data: Dict[str, pd.DataFrame]):
        """Th·ª±c hi·ªán c√°c quy·∫øt ƒë·ªãnh giao d·ªãch"""
        
        action_type = decision.get('action_type', 'hold')
        
        if action_type == 'hold':
            return
        
        # Handle position sizing v√† execution
        for symbol, df in market_data.items():
            if df.empty:
                continue
            
            # Get current price v√† ATR
            current_price = df['close'].iloc[-1]
            atr = df['atr'].iloc[-1] if 'atr' in df.columns else current_price * 0.01
            
            # Calculate position size
            position_info = self.risk_manager.calculate_position_size(
                symbol=symbol,
                signal_strength=decision.get('signal_strength', 0),
                confidence=decision.get('confidence', 0),
                atr=atr,
                sentiment_score=decision.get('sentiment_score', 0)
            )
            
            # Validate trade
            validation = self.risk_manager.validate_trade(
                symbol=symbol,
                position_size=position_info['suggested_size'],
                position_type=action_type,
                current_price=current_price
            )
            
            if validation['allowed']:
                # Execute trade
                position_data = {
                    'size': position_info['suggested_size'] if action_type == 'buy' else -position_info['suggested_size'],
                    'entry_price': current_price,
                  'current_price': current_price,
                    'stop_loss': current_price - position_info['stop_loss_distance'] if action_type == 'buy' else current_price + position_info['stop_loss_distance'],
                    'take_profit': current_price + position_info['take_profit_distance'] if action_type == 'buy' else current_price - position_info['take_profit_distance'],
                    'position_type': action_type,
                    'risk_percentage': position_info['risk_percentage']
                }
                
                # Update position trong risk manager
                self.risk_manager.update_position(symbol, position_data)
                
                # Send Discord notification
                await self.discord_manager.send_position_opened(symbol, position_data)
                
                self.logger.info(f"‚úÖ Trade executed: {action_type.upper()} {symbol} @ {current_price:.4f}")
                
            else:
                reasons = validation.get('reasons', [])
                self.logger.warning(f"üö´ Trade rejected for {symbol}: {', '.join(reasons)}")
    
    async def _initial_model_training(self):
        """Perform initial training for AI models if they're not trained yet"""
        
        try:
            if not self.running:
                return
                
            self.logger.info("üéì Checking AI model training status...")
            
            # Check if models need initial training
            ensemble_trained = (self.ensemble_model and 
                             hasattr(self.ensemble_model, 'models') and 
                             self.ensemble_model.models and 
                             hasattr(self.ensemble_model, 'meta_model') and 
                             self.ensemble_model.meta_model)
            
            lstm_trained = (self.lstm_model and 
                          hasattr(self.lstm_model, 'is_trained') and 
                          self.lstm_model.is_trained)
            
            if ensemble_trained and lstm_trained:
                self.logger.info("‚úÖ AI models are already trained!")
                return
            
            # Fetch historical data for initial training
            self.logger.info("üìä Fetching historical data for initial training...")
            historical_data = await self._fetch_initial_training_data()
            
            if not historical_data:
                self.logger.warning("‚ö†Ô∏è No historical data available for initial training")
                return
            
            # CRITICAL FIX: Engineer all features for training data to match prediction features
            self.logger.info("üîß Engineering features for training data to match prediction features...")
            enriched_training_data = {}
            for symbol, df in historical_data.items():
                if len(df) > 100:  # Need sufficient data
                    # Apply the same feature engineering as used during prediction
                    enriched_df = self.feature_engineer.engineer_all_features(df, symbol)
                    enriched_training_data[symbol] = enriched_df
                    self.logger.info(f"‚úÖ Engineered features for {symbol}: {enriched_df.shape[1]} features")
            
            # Train ensemble model if needed
            if not ensemble_trained:
                self.logger.info("ü§ñ Training ensemble model...")
                try:
                    for symbol, enriched_df in enriched_training_data.items():
                        if len(enriched_df) > 100:  # Need sufficient data
                            # Prepare features and targets from enriched data
                            features_df = enriched_df.select_dtypes(include=[np.number]).dropna()
                            if len(features_df) > 50:
                                targets = self._create_training_targets(enriched_df)
                                if targets is not None:
                                    self.logger.info(f"Training ensemble model with {symbol}: {features_df.shape[1]} features")
                                    await self.master_agent.trigger_ai_training(symbol, enriched_df)
                                    break  # Train on one symbol initially
                except Exception as e:
                    self.logger.warning(f"Ensemble model training failed: {e}")
            
            # Train LSTM model if needed
            if not lstm_trained:
                self.logger.info("üß† Training LSTM model...")
                try:
                    for symbol, enriched_df in enriched_training_data.items():
                        if len(enriched_df) > 100:  # Need sufficient data for LSTM
                            # Use the same enriched features as during prediction
                            features_df = enriched_df.select_dtypes(include=[np.number]).dropna()
                            if len(features_df) > 50:
                                targets = self._create_training_targets(enriched_df)
                                if targets is not None and len(targets) == len(features_df):
                                    self.logger.info(f"Training LSTM model with {symbol}: features shape={features_df.shape}, targets shape={targets.shape}")
                                    self.logger.info(f"LSTM training features: {list(features_df.columns)}")
                                    # Train LSTM model
                                    training_result = self.lstm_model.train(features_df, targets)
                                    if training_result.get('training_completed', False):
                                        self.logger.info("‚úÖ LSTM model trained successfully!")
                                        break
                                    else:
                                        self.logger.warning(f"Training failed for {symbol}: {training_result}")
                                else:
                                    self.logger.warning(f"Skipping {symbol}: features/{len(features_df)}, targets/{len(targets) if targets is not None else 'None'}")
                except Exception as e:
                    self.logger.warning(f"LSTM model training failed: {e}")
            
            # Train RL Agent if needed
            if not self.rl_agent or not self.rl_agent.model:
                self.logger.info("ü§ñ Training RL Agent with real trading environment...")
                try:
                    # Use the first symbol with sufficient data for RL training
                    for symbol, enriched_df in enriched_training_data.items():
                        if len(enriched_df) > 200:  # Need more data for RL training
                            self.logger.info(f"Creating RealTradingEnv for {symbol} with {len(enriched_df)} candles")
                            
                            # Create RealTradingEnv with historical data
                            trading_env = RealTradingEnv(
                                data_manager=self.data_manager,
                                historical_data=enriched_df,
                                symbol=symbol,
                                feature_engineer=self.feature_engineer
                            )
                            
                            # Initialize RL Agent with real environment
                            self.rl_agent = RLAgent(trading_env)
                            self.rl_agent.create_model()
                            
                            # Train RL Agent
                            self.logger.info(f"Starting RL training for {symbol}...")
                            rl_result = self.rl_agent.train(total_timesteps=100000)
                            
                            if 'error' in rl_result:
                                self.logger.error(f"‚ùå RL training failed: {rl_result['error']}")
                            else:
                                self.logger.info("‚úÖ RL Agent training completed successfully!")
                                break  # Train on one symbol initially
                        else:
                            self.logger.warning(f"Skipping {symbol}: insufficient data for RL training ({len(enriched_df)} candles)")
                            
                except Exception as e:
                    self.logger.warning(f"RL Agent training failed: {e}")
            
            self.logger.info("üéì Initial model training completed!")
            
        except Exception as e:
            self.logger.error(f"‚ùå Initial model training failed: {e}")
    
    async def _fetch_initial_training_data(self) -> Dict[str, pd.DataFrame]:
        """Fetch historical data for initial model training"""
        
        try:
            historical_data = {}
            
            # Use up to 2 symbols for initial training
            symbols = Config.SYMBOLS[:2]
            
            async with self.api_manager as api_mgr:
                for symbol in symbols:
                    try:
                        # Fetch data for multiple timeframes
                        df = await self.data_manager.get_fresh_data(symbol, 'H1')
                        if df is not None and len(df) > 50:
                            historical_data[symbol] = df
                            self.logger.info(f"üìà Fetched {len(df)} historical records for {symbol}")
                    except Exception as e:
                        self.logger.warning(f"Could not fetch training data for {symbol}: {e}")
                        continue
            
            return historical_data
            
        except Exception as e:
            self.logger.error(f"‚ùå Error fetching initial training data: {e}")
            return {}
    
    def _create_training_targets(self, df: pd.DataFrame) -> Optional[pd.Series]:
        """Create training targets using Triple-Barrier Method"""
        
        try:
            if len(df) < 20 or 'close' not in df.columns or 'high' not in df.columns or 'low' not in df.columns:
                return None
            
            # Calculate ATR (Average True Range) for volatility measurement
            def calculate_atr(df, period=14):
                """Calculate ATR using pandas operations"""
                high_low = df['high'] - df['low']
                high_close_prev = abs(df['high'] - df['close'].shift(1))
                low_close_prev = abs(df['low'] - df['close'].shift(1))
                
                true_range = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)
                atr = true_range.rolling(window=period).mean()
                return atr
            
            # Calculate ATR
            atr = calculate_atr(df)
            
            # Triple-Barrier Method parameters
            take_profit_multiplier = 2.0  # ATR multiplier for take profit
            stop_loss_multiplier = 1.5   # ATR multiplier for stop loss
            time_barrier = 10            # Number of candles to look ahead
            
            targets = []
            
            # Process each candle
            for i in range(len(df) - time_barrier):
                current_price = df['close'].iloc[i]
                current_atr = atr.iloc[i]
                
                # Skip if ATR is not available (NaN)
                if pd.isna(current_atr) or current_atr == 0:
                    targets.append(2)  # Default to HOLD
                    continue
                
                # Define barriers
                take_profit_barrier = current_price + (current_atr * take_profit_multiplier)
                stop_loss_barrier = current_price - (current_atr * stop_loss_multiplier)
                
                # Look ahead for the next N candles
                take_profit_hit = False
                stop_loss_hit = False
                
                for j in range(i + 1, min(i + 1 + time_barrier, len(df))):
                    candle_high = df['high'].iloc[j]
                    candle_low = df['low'].iloc[j]
                    
                    # Check if take profit barrier is hit first
                    if candle_high >= take_profit_barrier and not stop_loss_hit:
                        take_profit_hit = True
                        break
                    
                    # Check if stop loss barrier is hit first
                    if candle_low <= stop_loss_barrier and not take_profit_hit:
                        stop_loss_hit = True
                        break
                
                # Assign labels based on barrier hits
                if take_profit_hit:
                    targets.append(1)  # BUY signal
                elif stop_loss_hit:
                    targets.append(0)  # SELL signal
                else:
                    targets.append(2)  # HOLD signal
            
            # Add placeholder targets for the last N candles (can't look ahead)
            for _ in range(time_barrier):
                targets.append(2)  # Default to HOLD for last candles
            
            # Create Series with proper index
            target_series = pd.Series(targets, name='target', index=df.index)
            
            # Log target distribution for monitoring
            target_counts = target_series.value_counts()
            self.logger.info(f"Training targets distribution: {target_counts.to_dict()}")
            
            return target_series
            
        except Exception as e:
            self.logger.error(f"Error creating training targets with Triple-Barrier Method: {e}")
            return None
    
    async def _update_models_with_new_data(self, enriched_data: Dict[str, pd.DataFrame]):
        """C·∫≠p nh·∫≠t models v·ªõi d·ªØ li·ªáu m·ªõi"""
        
        try:
            # Update online learning models
            for symbol, df in enriched_data.items():
                # Make sure df is a DataFrame, not a dict
                if isinstance(df, dict):
                    # Skip dict entries - they should be timeframes
                    continue
                    
                if hasattr(df, 'empty') and not df.empty and len(df) > Config.FEATURE_WINDOW:
                    # Get latest features
                    latest_row = df.iloc[-1:].select_dtypes(include=[np.number])
                    latest_features = latest_row.values[0] if not latest_row.empty else np.array([])
                    
                    # Create target (simplified: +1 if price went up next period, 0 otherwise)
                    if len(df) > 1:
                        # Handle different column naming patterns
                        price_columns = [col for col in df.columns if 'close' in col.lower()]
                        if price_columns:
                            price_col = price_columns[0]  # Use first close column found
                            current_price = df[price_col].iloc[-1]
                            next_price = df[price_col].iloc[-2]
                            target = 1 if current_price > next_price else 0
                        else:
                            target = 0  # Default if no price column found
                        
                        self.auto_retrain_manager.online_manager.update_model(symbol, latest_features, float(target))
            
            self.logger.info("üìà Models updated with new data")
            
        except Exception as e:
            self.logger.error(f"L·ªói c·∫≠p nh·∫≠t models: {e}")
    
    async def _check_retrain_conditions(self, market_data: Dict[str, pd.DataFrame]):
        """Ki·ªÉm tra ƒëi·ªÅu ki·ªán retrain"""
        
        try:
            # Combine all market data for drift detection
            combined_data = pd.DataFrame()
            
            for symbol, df in market_data.items():
                # Ensure df is a DataFrame and not empty
                if isinstance(df, pd.DataFrame) and not df.empty:
                    symbol_data = df.copy()
                    symbol_data['symbol'] = symbol
                    combined_data = pd.concat([combined_data, symbol_data], ignore_index=True)
                elif isinstance(df, dict):
                    # Skip dict entries - convert to DataFrame if possible
                    try:
                        temp_df = pd.DataFrame([df])
                        if len(temp_df) > 0:
                            temp_df['symbol'] = symbol
                            combined_data = pd.concat([combined_data, temp_df], ignore_index=True)
                    except Exception:
                        continue  # Skip if conversion fails
            
            if isinstance(combined_data, pd.DataFrame) and not combined_data.empty:
                retrain_conditions = self.auto_retrain_manager.check_retrain_conditions(combined_data)
                
                if retrain_conditions['should_retrain']:
                    self.logger.info("üîÑ Retrain conditions met, preparing retrain..")
                    
                    # Simplified retrain v·ªõi sample data
                    sample_data = combined_data.select_dtypes(include=[np.number]).dropna()
                    if len(sample_data) > 100:
                        X_sample = sample_data.iloc[:-1]
                        y_sample = pd.Series([1 if sample_data.iloc[i+1]['close'] > sample_data.head(i+1)['close'].mean() else 0 
                                            for i in range(len(X_sample))], index=X_sample.index)
                        
                        retrain_results = self.auto_retrain_manager.execute_retrain(X_sample, y_sample)
                        
                        if retrain_results['retrain_success']:
                            self.logger.info(f"‚úÖ Retrain completed - Improvement: {retrain_results['improvement']:.3f}")
            
        except Exception as e:
            self.logger.error(f"L·ªói ki·ªÉm tra retrain conditions: {e}")
    
    async def _report_performance(self):
        """B√°o c√°o hi·ªáu su·∫•t ƒë·ªãnh k·ª≥"""
        
        try:
            # Calculate portfolio metrics
            portfolio_metrics = self.risk_manager.calculate_portfolio_metrics()
            
            # Get model diagnostics
            model_diagnostics = self.auto_retrain_manager.get_model_diagnostics()
            
            # Send Discord report
            await self.discord_manager.send_performance_report(portfolio_metrics, model_diagnostics)
            
            self.logger.info("üìä Performance report sent")
            
        except Exception as e:
            self.logger.error(f"L·ªói g·ª≠i b√°o c√°o performance: {e}")
    
    async def start(self, cycle_interval_minutes: int = 60):
        """Kh·ªüi ƒë·ªông bot v√† b·∫Øt ƒë·∫ßu trading loop"""
        
        if self.running:
            self.logger.warning("Bot is already running")
            return
        
        self.running = True
        self.trading_session_start = datetime.now()
        
        self.logger.info(f"üöÄ Starting Trading Bot (cycle interval: {cycle_interval_minutes} minutes)")
        
        try:
            # Initialize all components
            await self.initialize()
            
            # Perform initial training if models are not trained
            await self._initial_model_training()
            
            # Start real-time monitoring
            if self.real_time_monitor:
                self.real_time_monitor.start_monitoring()
            
            # Main trading loop
            while self.running:
                try:
                    await self.run_trading_cycle()
                    
                    # Wait for next cycle
                    await asyncio.sleep(cycle_interval_minutes * 60)
                    
                except KeyboardInterrupt:
                    self.logger.info("Received interrupt signal")
                    break
                except Exception as e:
                    self.logger.error(f"Unexpected error in trading loop: {e}")
                    await asyncio.sleep(60)  # Wait 1 minute before retry
            
        except Exception as e:
            self.logger.error(f"Critical error starting bot: {e}")
            await self.discord_manager.send_error_notification("Critical Startup Error", str(e))
            raise
        
        finally:
            await self.stop()
    
    async def stop(self):
        """D·ª´ng bot v√† cleanup"""
        
        self.logger.info("üõë Stopping Trading Bot...")
        self.running = False
        
        try:
            # Stop real-time monitoring
            if self.real_time_monitor:
                self.real_time_monitor.stop_monitoring()
            
            # Close all connections
            if self.api_manager:
                await self.api_manager.__aexit__(None, None, None)
            
            # Send shutdown notification
            embed_data = {
                "title": "‚èπÔ∏è Trading Bot Stopped",
                "description": f"Trading Bot has been shut down after {self.cycle_count} cycles",
                "color": 0xff8800,
                "timestamp": datetime.now().isoformat(),
                "footer": {"text": "Session Ended"}
            }
            
            await self.discord_manager._send_embed(embed_data)
            
            self.logger.info("‚úÖ Trading Bot stopped successfully")
            
        except Exception as e:
            self.logger.error(f"L·ªói trong stop process: {e}")

# ===== MAIN EXECUTION =====
async def main():
    """H√†m main c·ªßa ch∆∞∆°ng tr√¨nh"""
    
    try:
        # Create v√† start trading bot
        trading_bot = TradingBotController()
        
        # Start bot v·ªõi cycle interval 60 minutes
        await trading_bot.start(cycle_interval_minutes=60)
        
    except Exception as e:
        logger = LOG_MANAGER.get_logger('BotCore')
        logger.error(f"Fatal error in main: {e}")
        print(f"‚ùå Fatal error: {e}")
        
        # Send emergency notification
        try:
            discord_manager = DiscordNotificationManager()
            await discord_manager.send_error_notification("Fatal System Error", str(e))
        except:
            pass  # Don't fail if Discord notification fails

if __name__ == "__main__":
    """
    Trading Bot AI/ML Startup
    ========================
    
    T√≠nh nƒÉng ch√≠nh:
    - Ensemble ML models v·ªõi AutoML optimization
    - LSTM v·ªõi Attention mechanism
    - Reinforcement Learning v·ªõi PPO
    - Multi-specialist agent architecture
    - Advanced risk management
    - Real-time monitoring v√† auto SL/TP
    - News sentiment analysis v·ªõi AI
    - Concept drift detection v√† auto retrain
    - Discord notifications v√† monitoring
    """
    
    print("üöÄ Starting AI/ML Trading Bot...")
    print("=" * 50)
    
    try:
        # Run main function
        asyncio.run(main())
        
    except KeyboardInterrupt:
        print("\nüõë Received interrupt signal")
        print("Shutting down gracefully...")
        
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        
    finally:
        print("üëã Trading Bot stopped")
        print("Thank you for using AI/ML Trading Bot v2.0")